{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oHFCsV0z-Jw"
   },
   "source": [
    "# LLaMA Factory Colab Tutorial\n",
    "\n",
    "Project homepage: https://github.com/hiyouga/LLaMA-Factory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lr7rB3szzhtx"
   },
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "giM74oK1rRIH",
    "outputId": "09770c44-2d8a-42e5-dee6-ed159b57749e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /beegfs/home/users/h/huju/dev/BA/repos/LLaMA-Factory-SQL\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.13.1 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from llmtuner==0.6.0) (2.2.1)\n",
      "Requirement already satisfied: transformers>=4.37.2 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from llmtuner==0.6.0) (4.39.1)\n",
      "Requirement already satisfied: datasets>=2.14.3 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from llmtuner==0.6.0) (2.18.0)\n",
      "Requirement already satisfied: accelerate>=0.27.2 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from llmtuner==0.6.0) (0.28.0)\n",
      "Requirement already satisfied: peft>=0.9.0 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from llmtuner==0.6.0) (0.10.0)\n",
      "Requirement already satisfied: trl>=0.8.1 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from llmtuner==0.6.0) (0.8.1)\n",
      "Requirement already satisfied: gradio<4.0.0,>=3.38.0 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from llmtuner==0.6.0) (3.50.2)\n",
      "Requirement already satisfied: scipy in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from llmtuner==0.6.0) (1.12.0)\n",
      "Requirement already satisfied: einops in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from llmtuner==0.6.0) (0.7.0)\n",
      "Requirement already satisfied: sentencepiece in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from llmtuner==0.6.0) (0.2.0)\n",
      "Requirement already satisfied: protobuf in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from llmtuner==0.6.0) (5.26.0)\n",
      "Requirement already satisfied: uvicorn in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from llmtuner==0.6.0) (0.29.0)\n",
      "Requirement already satisfied: pydantic in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from llmtuner==0.6.0) (2.6.4)\n",
      "Requirement already satisfied: fastapi in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from llmtuner==0.6.0) (0.110.0)\n",
      "Requirement already satisfied: sse-starlette in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from llmtuner==0.6.0) (2.0.0)\n",
      "Requirement already satisfied: matplotlib in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from llmtuner==0.6.0) (3.8.3)\n",
      "Requirement already satisfied: fire in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from llmtuner==0.6.0) (0.6.0)\n",
      "Requirement already satisfied: galore-torch in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from llmtuner==0.6.0) (1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from accelerate>=0.27.2->llmtuner==0.6.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from accelerate>=0.27.2->llmtuner==0.6.0) (24.0)\n",
      "Requirement already satisfied: psutil in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from accelerate>=0.27.2->llmtuner==0.6.0) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from accelerate>=0.27.2->llmtuner==0.6.0) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from accelerate>=0.27.2->llmtuner==0.6.0) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from accelerate>=0.27.2->llmtuner==0.6.0) (0.4.2)\n",
      "Requirement already satisfied: filelock in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from datasets>=2.14.3->llmtuner==0.6.0) (3.13.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from datasets>=2.14.3->llmtuner==0.6.0) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from datasets>=2.14.3->llmtuner==0.6.0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from datasets>=2.14.3->llmtuner==0.6.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from datasets>=2.14.3->llmtuner==0.6.0) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from datasets>=2.14.3->llmtuner==0.6.0) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from datasets>=2.14.3->llmtuner==0.6.0) (4.66.2)\n",
      "Requirement already satisfied: xxhash in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from datasets>=2.14.3->llmtuner==0.6.0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from datasets>=2.14.3->llmtuner==0.6.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets>=2.14.3->llmtuner==0.6.0) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from datasets>=2.14.3->llmtuner==0.6.0) (3.9.3)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from gradio<4.0.0,>=3.38.0->llmtuner==0.6.0) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from gradio<4.0.0,>=3.38.0->llmtuner==0.6.0) (5.2.0)\n",
      "Requirement already satisfied: ffmpy in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from gradio<4.0.0,>=3.38.0->llmtuner==0.6.0) (0.3.2)\n",
      "Requirement already satisfied: gradio-client==0.6.1 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from gradio<4.0.0,>=3.38.0->llmtuner==0.6.0) (0.6.1)\n",
      "Requirement already satisfied: httpx in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from gradio<4.0.0,>=3.38.0->llmtuner==0.6.0) (0.27.0)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from gradio<4.0.0,>=3.38.0->llmtuner==0.6.0) (6.4.0)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from gradio<4.0.0,>=3.38.0->llmtuner==0.6.0) (3.1.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from gradio<4.0.0,>=3.38.0->llmtuner==0.6.0) (2.1.5)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from gradio<4.0.0,>=3.38.0->llmtuner==0.6.0) (3.9.15)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from gradio<4.0.0,>=3.38.0->llmtuner==0.6.0) (10.2.0)\n",
      "Requirement already satisfied: pydub in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from gradio<4.0.0,>=3.38.0->llmtuner==0.6.0) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from gradio<4.0.0,>=3.38.0->llmtuner==0.6.0) (0.0.9)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from gradio<4.0.0,>=3.38.0->llmtuner==0.6.0) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from gradio<4.0.0,>=3.38.0->llmtuner==0.6.0) (4.10.0)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from gradio<4.0.0,>=3.38.0->llmtuner==0.6.0) (11.0.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from matplotlib->llmtuner==0.6.0) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from matplotlib->llmtuner==0.6.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from matplotlib->llmtuner==0.6.0) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from matplotlib->llmtuner==0.6.0) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from matplotlib->llmtuner==0.6.0) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from matplotlib->llmtuner==0.6.0) (2.9.0.post0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from pydantic->llmtuner==0.6.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from pydantic->llmtuner==0.6.0) (2.16.3)\n",
      "Requirement already satisfied: sympy in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from torch>=1.13.1->llmtuner==0.6.0) (1.12)\n",
      "Requirement already satisfied: networkx in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from torch>=1.13.1->llmtuner==0.6.0) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from torch>=1.13.1->llmtuner==0.6.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from torch>=1.13.1->llmtuner==0.6.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from torch>=1.13.1->llmtuner==0.6.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from torch>=1.13.1->llmtuner==0.6.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from torch>=1.13.1->llmtuner==0.6.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from torch>=1.13.1->llmtuner==0.6.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from torch>=1.13.1->llmtuner==0.6.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from torch>=1.13.1->llmtuner==0.6.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from torch>=1.13.1->llmtuner==0.6.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from torch>=1.13.1->llmtuner==0.6.0) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from torch>=1.13.1->llmtuner==0.6.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from torch>=1.13.1->llmtuner==0.6.0) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.1->llmtuner==0.6.0) (12.4.99)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from transformers>=4.37.2->llmtuner==0.6.0) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from transformers>=4.37.2->llmtuner==0.6.0) (0.15.2)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from trl>=0.8.1->llmtuner==0.6.0) (0.7.3)\n",
      "Requirement already satisfied: click>=7.0 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from uvicorn->llmtuner==0.6.0) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from uvicorn->llmtuner==0.6.0) (0.14.0)\n",
      "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from fastapi->llmtuner==0.6.0) (0.36.3)\n",
      "Requirement already satisfied: six in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from fire->llmtuner==0.6.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from fire->llmtuner==0.6.0) (2.4.0)\n",
      "Requirement already satisfied: bitsandbytes in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from galore-torch->llmtuner==0.6.0) (0.43.0)\n",
      "Requirement already satisfied: anyio in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from sse-starlette->llmtuner==0.6.0) (4.3.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio<4.0.0,>=3.38.0->llmtuner==0.6.0) (4.21.1)\n",
      "Requirement already satisfied: toolz in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio<4.0.0,>=3.38.0->llmtuner==0.6.0) (0.12.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from aiohttp->datasets>=2.14.3->llmtuner==0.6.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from aiohttp->datasets>=2.14.3->llmtuner==0.6.0) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from aiohttp->datasets>=2.14.3->llmtuner==0.6.0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from aiohttp->datasets>=2.14.3->llmtuner==0.6.0) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from aiohttp->datasets>=2.14.3->llmtuner==0.6.0) (1.9.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from pandas->datasets>=2.14.3->llmtuner==0.6.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from pandas->datasets>=2.14.3->llmtuner==0.6.0) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.14.3->llmtuner==0.6.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.14.3->llmtuner==0.6.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.14.3->llmtuner==0.6.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.14.3->llmtuner==0.6.0) (2024.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from anyio->sse-starlette->llmtuner==0.6.0) (1.3.1)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from tyro>=0.5.11->trl>=0.8.1->llmtuner==0.6.0) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from tyro>=0.5.11->trl>=0.8.1->llmtuner==0.6.0) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from tyro>=0.5.11->trl>=0.8.1->llmtuner==0.6.0) (1.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from httpx->gradio<4.0.0,>=3.38.0->llmtuner==0.6.0) (1.0.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from sympy->torch>=1.13.1->llmtuner==0.6.0) (1.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio<4.0.0,>=3.38.0->llmtuner==0.6.0) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio<4.0.0,>=3.38.0->llmtuner==0.6.0) (0.34.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio<4.0.0,>=3.38.0->llmtuner==0.6.0) (0.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl>=0.8.1->llmtuner==0.6.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl>=0.8.1->llmtuner==0.6.0) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/users/h/huju/miniconda3/envs/BA-LLaMA-Factory-SQL/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl>=0.8.1->llmtuner==0.6.0) (0.1.2)\n",
      "Building wheels for collected packages: llmtuner\n",
      "  Building wheel for llmtuner (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llmtuner: filename=llmtuner-0.6.0-py3-none-any.whl size=137565 sha256=1be18b47f59edec624b5bf6d0a16ef038a2f9561a85c8d696fe24e2147147db2\n",
      "  Stored in directory: /beegfs/home/users/h/huju/.cache/pip/wheels/b6/63/62/e4fd31fc44f96b04f0ae8b27883292207992098c535ca9794c\n",
      "Successfully built llmtuner\n",
      "Installing collected packages: llmtuner\n",
      "  Attempting uninstall: llmtuner\n",
      "    Found existing installation: llmtuner 0.6.0\n",
      "    Uninstalling llmtuner-0.6.0:\n",
      "      Successfully uninstalled llmtuner-0.6.0\n",
      "Successfully installed llmtuner-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9RXn_YQnn9f"
   },
   "source": [
    "### Check GPU environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZkN-ktlsnrdU"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "try:\n",
    "  assert torch.cuda.is_available() is True\n",
    "except AssertionError:\n",
    "  print(\"Please set up a GPU before using LLaMA Factory: https://medium.com/mlearning-ai/training-yolov4-on-google-colab-316f8fff99c6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okkbTMoZCQNf"
   },
   "source": [
    "### Log in with Hugging Face account to upload model (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6OIm0O7oA5sy",
    "outputId": "b2e96bdb-32ee-4ced-8da7-8947897a58ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hujudev\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QiXcvdzzW3Y"
   },
   "source": [
    "## Fine-tune model via LLaMA Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YLsdS6V5yUMy",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/h/huju/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://e091599d9ce93348fa.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://e091599d9ce93348fa.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/26/2024 16:54:39 - INFO - llmtuner.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: torch.float16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:2084] 2024-03-26 16:54:42,284 >> loading file tokenizer.model from cache at /home/users/h/huju/.cache/huggingface/hub/models--codellama--CodeLlama-7b-hf/snapshots/7f22f0a5f7991355a2c3867923359ec4ed0b58bf/tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2084] 2024-03-26 16:54:42,285 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2084] 2024-03-26 16:54:42,286 >> loading file special_tokens_map.json from cache at /home/users/h/huju/.cache/huggingface/hub/models--codellama--CodeLlama-7b-hf/snapshots/7f22f0a5f7991355a2c3867923359ec4ed0b58bf/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2084] 2024-03-26 16:54:42,287 >> loading file tokenizer_config.json from cache at /home/users/h/huju/.cache/huggingface/hub/models--codellama--CodeLlama-7b-hf/snapshots/7f22f0a5f7991355a2c3867923359ec4ed0b58bf/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2084] 2024-03-26 16:54:42,288 >> loading file tokenizer.json from cache at /home/users/h/huju/.cache/huggingface/hub/models--codellama--CodeLlama-7b-hf/snapshots/7f22f0a5f7991355a2c3867923359ec4ed0b58bf/tokenizer.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/26/2024 16:54:43 - INFO - llmtuner.data.template - Add pad token: </s>\n",
      "03/26/2024 16:54:43 - INFO - llmtuner.data.loader - Loading dataset b-mc2/sql-create-context...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|███████████████████████████████████████████████████████████████████████████████| 4.43k/4.43k [00:00<00:00, 11.0MB/s]\n",
      "Downloading data: 100%|█████████████████████████████████████████████████████████████████████████████████| 21.8M/21.8M [00:00<00:00, 45.0MB/s]\n",
      "Generating train split: 78577 examples [00:00, 164560.00 examples/s]\n",
      "Converting format of dataset: 100%|██████████████████████████████████████████████████████████| 78577/78577 [00:01<00:00, 76184.18 examples/s]\n",
      "Running tokenizer on dataset: 100%|███████████████████████████████████████████████████████████| 78577/78577 [00:48<00:00, 1627.70 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids:\n",
      "[12968, 29901, 1128, 1784, 15883, 310, 278, 5840, 1860, 526, 9642, 1135, 29871, 29945, 29953, 1577, 13, 27045, 10911, 2343, 313, 482, 2672, 4330, 17070, 29897, 13, 7900, 22137, 29901, 29871, 5097, 21122, 22798, 3895, 2343, 5754, 5046, 1405, 29871, 29945, 29953, 2]\n",
      "inputs:\n",
      "Human: How many heads of the departments are older than 56 ?\n",
      "CREATE TABLE head (age INTEGER)\n",
      "Assistant:  SELECT COUNT(*) FROM head WHERE age > 56</s>\n",
      "label_ids:\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 5097, 21122, 22798, 3895, 2343, 5754, 5046, 1405, 29871, 29945, 29953, 2]\n",
      "labels:\n",
      "SELECT COUNT(*) FROM head WHERE age > 56</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-03-26 16:55:43,804 >> loading configuration file config.json from cache at /home/users/h/huju/.cache/huggingface/hub/models--codellama--CodeLlama-7b-hf/snapshots/7f22f0a5f7991355a2c3867923359ec4ed0b58bf/config.json\n",
      "[INFO|configuration_utils.py:789] 2024-03-26 16:55:43,807 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"codellama/CodeLlama-7b-hf\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 16384,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.39.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32016\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3283] 2024-03-26 16:55:46,093 >> loading weights file model.safetensors from cache at /home/users/h/huju/.cache/huggingface/hub/models--codellama--CodeLlama-7b-hf/snapshots/7f22f0a5f7991355a2c3867923359ec4ed0b58bf/model.safetensors.index.json\n",
      "Downloading shards: 100%|██████████████████████████████████████████████████████████████████████████████████████| 2/2 [02:17<00:00, 68.63s/it]\n",
      "[INFO|modeling_utils.py:1417] 2024-03-26 16:58:03,363 >> Instantiating LlamaForCausalLM model under default dtype torch.float16.\n",
      "[INFO|configuration_utils.py:928] 2024-03-26 16:58:03,367 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2\n",
      "}\n",
      "\n",
      "Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████| 2/2 [00:07<00:00,  3.95s/it]\n",
      "[INFO|modeling_utils.py:4024] 2024-03-26 16:58:12,105 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4032] 2024-03-26 16:58:12,106 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at codellama/CodeLlama-7b-hf.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:883] 2024-03-26 16:58:12,430 >> loading configuration file generation_config.json from cache at /home/users/h/huju/.cache/huggingface/hub/models--codellama--CodeLlama-7b-hf/snapshots/7f22f0a5f7991355a2c3867923359ec4ed0b58bf/generation_config.json\n",
      "[INFO|configuration_utils.py:928] 2024-03-26 16:58:12,431 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/26/2024 16:58:12 - INFO - llmtuner.model.patcher - Gradient checkpointing enabled.\n",
      "03/26/2024 16:58:12 - INFO - llmtuner.model.adapter - Fine-tuning method: LoRA\n",
      "03/26/2024 16:58:13 - INFO - llmtuner.model.loader - trainable params: 4194304 || all params: 6742740992 || trainable%: 0.0622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/h/huju/miniconda3/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:607] 2024-03-26 16:58:13,258 >> Using auto half precision backend\n",
      "[INFO|trainer.py:1969] 2024-03-26 16:58:13,508 >> ***** Running training *****\n",
      "[INFO|trainer.py:1970] 2024-03-26 16:58:13,509 >>   Num examples = 78,577\n",
      "[INFO|trainer.py:1971] 2024-03-26 16:58:13,510 >>   Num Epochs = 3\n",
      "[INFO|trainer.py:1972] 2024-03-26 16:58:13,510 >>   Instantaneous batch size per device = 2\n",
      "[INFO|trainer.py:1975] 2024-03-26 16:58:13,511 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "[INFO|trainer.py:1976] 2024-03-26 16:58:13,511 >>   Gradient Accumulation steps = 8\n",
      "[INFO|trainer.py:1977] 2024-03-26 16:58:13,512 >>   Total optimization steps = 14,733\n",
      "[INFO|trainer.py:1978] 2024-03-26 16:58:13,515 >>   Number of trainable parameters = 4,194,304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/26/2024 16:58:34 - INFO - llmtuner.extras.callbacks - {'loss': 0.8710, 'learning_rate': 5.0000e-05, 'epoch': 0.00}\n",
      "{'loss': 0.871, 'grad_norm': 0.45025932788848877, 'learning_rate': 4.999998579087456e-05, 'epoch': 0.0}\n",
      "03/26/2024 16:58:47 - INFO - llmtuner.extras.callbacks - {'loss': 0.8951, 'learning_rate': 5.0000e-05, 'epoch': 0.00}\n",
      "{'loss': 0.8951, 'grad_norm': 0.5594398975372314, 'learning_rate': 4.9999943163514404e-05, 'epoch': 0.0}\n",
      "03/26/2024 16:59:00 - INFO - llmtuner.extras.callbacks - {'loss': 0.7065, 'learning_rate': 5.0000e-05, 'epoch': 0.00}\n",
      "{'loss': 0.7065, 'grad_norm': 0.6532801985740662, 'learning_rate': 4.999987211796797e-05, 'epoch': 0.0}\n",
      "03/26/2024 16:59:13 - INFO - llmtuner.extras.callbacks - {'loss': 0.6361, 'learning_rate': 5.0000e-05, 'epoch': 0.00}\n",
      "{'loss': 0.6361, 'grad_norm': 0.7719067335128784, 'learning_rate': 4.999977265431603e-05, 'epoch': 0.0}\n",
      "03/26/2024 16:59:26 - INFO - llmtuner.extras.callbacks - {'loss': 0.5191, 'learning_rate': 5.0000e-05, 'epoch': 0.01}\n",
      "{'loss': 0.5191, 'grad_norm': 0.46523207426071167, 'learning_rate': 4.999964477267164e-05, 'epoch': 0.01}\n",
      "03/26/2024 16:59:39 - INFO - llmtuner.extras.callbacks - {'loss': 0.4317, 'learning_rate': 4.9999e-05, 'epoch': 0.01}\n",
      "{'loss': 0.4317, 'grad_norm': 0.5668131709098816, 'learning_rate': 4.999948847318018e-05, 'epoch': 0.01}\n",
      "03/26/2024 16:59:51 - INFO - llmtuner.extras.callbacks - {'loss': 0.4021, 'learning_rate': 4.9999e-05, 'epoch': 0.01}\n",
      "{'loss': 0.4021, 'grad_norm': 0.47078317403793335, 'learning_rate': 4.999930375601931e-05, 'epoch': 0.01}\n",
      "03/26/2024 17:00:04 - INFO - llmtuner.extras.callbacks - {'loss': 0.3105, 'learning_rate': 4.9999e-05, 'epoch': 0.01}\n",
      "{'loss': 0.3105, 'grad_norm': 0.4301518201828003, 'learning_rate': 4.9999090621398996e-05, 'epoch': 0.01}\n",
      "03/26/2024 17:00:17 - INFO - llmtuner.extras.callbacks - {'loss': 0.2249, 'learning_rate': 4.9999e-05, 'epoch': 0.01}\n",
      "{'loss': 0.2249, 'grad_norm': 0.3510955274105072, 'learning_rate': 4.999884906956153e-05, 'epoch': 0.01}\n",
      "03/26/2024 17:00:29 - INFO - llmtuner.extras.callbacks - {'loss': 0.2523, 'learning_rate': 4.9999e-05, 'epoch': 0.01}\n",
      "{'loss': 0.2523, 'grad_norm': 0.3888135552406311, 'learning_rate': 4.9998579100781486e-05, 'epoch': 0.01}\n",
      "03/26/2024 17:00:42 - INFO - llmtuner.extras.callbacks - {'loss': 0.1982, 'learning_rate': 4.9998e-05, 'epoch': 0.01}\n",
      "{'loss': 0.1982, 'grad_norm': 0.3651486337184906, 'learning_rate': 4.999828071536574e-05, 'epoch': 0.01}\n",
      "03/26/2024 17:00:55 - INFO - llmtuner.extras.callbacks - {'loss': 0.1566, 'learning_rate': 4.9998e-05, 'epoch': 0.01}\n",
      "{'loss': 0.1566, 'grad_norm': 0.29361051321029663, 'learning_rate': 4.999795391365348e-05, 'epoch': 0.01}\n",
      "03/26/2024 17:01:07 - INFO - llmtuner.extras.callbacks - {'loss': 0.1613, 'learning_rate': 4.9998e-05, 'epoch': 0.01}\n",
      "{'loss': 0.1613, 'grad_norm': 0.42993417382240295, 'learning_rate': 4.99975986960162e-05, 'epoch': 0.01}\n",
      "03/26/2024 17:01:20 - INFO - llmtuner.extras.callbacks - {'loss': 0.1198, 'learning_rate': 4.9997e-05, 'epoch': 0.01}\n",
      "{'loss': 0.1198, 'grad_norm': 0.28437161445617676, 'learning_rate': 4.999721506285767e-05, 'epoch': 0.01}\n",
      "03/26/2024 17:01:32 - INFO - llmtuner.extras.callbacks - {'loss': 0.1087, 'learning_rate': 4.9997e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1087, 'grad_norm': 0.44723811745643616, 'learning_rate': 4.999680301461399e-05, 'epoch': 0.02}\n",
      "03/26/2024 17:01:45 - INFO - llmtuner.extras.callbacks - {'loss': 0.1188, 'learning_rate': 4.9996e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1188, 'grad_norm': 0.3264034390449524, 'learning_rate': 4.999636255175354e-05, 'epoch': 0.02}\n",
      "03/26/2024 17:01:57 - INFO - llmtuner.extras.callbacks - {'loss': 0.1300, 'learning_rate': 4.9996e-05, 'epoch': 0.02}\n",
      "{'loss': 0.13, 'grad_norm': 0.33257660269737244, 'learning_rate': 4.999589367477701e-05, 'epoch': 0.02}\n",
      "03/26/2024 17:02:09 - INFO - llmtuner.extras.callbacks - {'loss': 0.0975, 'learning_rate': 4.9995e-05, 'epoch': 0.02}\n",
      "{'loss': 0.0975, 'grad_norm': 0.29279452562332153, 'learning_rate': 4.9995396384217385e-05, 'epoch': 0.02}\n",
      "03/26/2024 17:02:21 - INFO - llmtuner.extras.callbacks - {'loss': 0.1120, 'learning_rate': 4.9995e-05, 'epoch': 0.02}\n",
      "{'loss': 0.112, 'grad_norm': 0.4012364447116852, 'learning_rate': 4.9994870680639955e-05, 'epoch': 0.02}\n",
      "03/26/2024 17:02:33 - INFO - llmtuner.extras.callbacks - {'loss': 0.1240, 'learning_rate': 4.9994e-05, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3203] 2024-03-26 17:02:33,949 >> Saving model checkpoint to saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.124, 'grad_norm': 0.4347827732563019, 'learning_rate': 4.9994316564642294e-05, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-03-26 17:02:34,750 >> loading configuration file config.json from cache at /home/users/h/huju/.cache/huggingface/hub/models--codellama--CodeLlama-7b-hf/snapshots/7f22f0a5f7991355a2c3867923359ec4ed0b58bf/config.json\n",
      "[INFO|configuration_utils.py:789] 2024-03-26 17:02:34,752 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"codellama/CodeLlama-7b-hf\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 16384,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.39.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32016\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2502] 2024-03-26 17:02:34,894 >> tokenizer config file saved in saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-100/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2511] 2024-03-26 17:02:34,898 >> Special tokens file saved in saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-100/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/26/2024 17:02:47 - INFO - llmtuner.extras.callbacks - {'loss': 0.1002, 'learning_rate': 4.9994e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1002, 'grad_norm': 0.5607318878173828, 'learning_rate': 4.9993734036854304e-05, 'epoch': 0.02}\n",
      "03/26/2024 17:02:59 - INFO - llmtuner.extras.callbacks - {'loss': 0.1013, 'learning_rate': 4.9993e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1013, 'grad_norm': 0.43622878193855286, 'learning_rate': 4.9993123097938134e-05, 'epoch': 0.02}\n",
      "03/26/2024 17:03:12 - INFO - llmtuner.extras.callbacks - {'loss': 0.0818, 'learning_rate': 4.9992e-05, 'epoch': 0.02}\n",
      "{'loss': 0.0818, 'grad_norm': 0.46151280403137207, 'learning_rate': 4.999248374858827e-05, 'epoch': 0.02}\n",
      "03/26/2024 17:03:24 - INFO - llmtuner.extras.callbacks - {'loss': 0.0702, 'learning_rate': 4.9992e-05, 'epoch': 0.02}\n",
      "{'loss': 0.0702, 'grad_norm': 0.4056316912174225, 'learning_rate': 4.9991815989531474e-05, 'epoch': 0.02}\n",
      "03/26/2024 17:03:36 - INFO - llmtuner.extras.callbacks - {'loss': 0.0817, 'learning_rate': 4.9991e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0817, 'grad_norm': 0.22662287950515747, 'learning_rate': 4.999111982152682e-05, 'epoch': 0.03}\n",
      "03/26/2024 17:03:49 - INFO - llmtuner.extras.callbacks - {'loss': 0.0814, 'learning_rate': 4.9990e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0814, 'grad_norm': 0.3878296911716461, 'learning_rate': 4.999039524536565e-05, 'epoch': 0.03}\n",
      "03/26/2024 17:04:01 - INFO - llmtuner.extras.callbacks - {'loss': 0.0788, 'learning_rate': 4.9990e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0788, 'grad_norm': 0.435202419757843, 'learning_rate': 4.9989642261871614e-05, 'epoch': 0.03}\n",
      "03/26/2024 17:04:13 - INFO - llmtuner.extras.callbacks - {'loss': 0.0995, 'learning_rate': 4.9989e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0995, 'grad_norm': 0.37939536571502686, 'learning_rate': 4.9988860871900665e-05, 'epoch': 0.03}\n",
      "03/26/2024 17:04:25 - INFO - llmtuner.extras.callbacks - {'loss': 0.0713, 'learning_rate': 4.9988e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0713, 'grad_norm': 0.3447073698043823, 'learning_rate': 4.9988051076341015e-05, 'epoch': 0.03}\n",
      "03/26/2024 17:04:38 - INFO - llmtuner.extras.callbacks - {'loss': 0.0641, 'learning_rate': 4.9987e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0641, 'grad_norm': 0.33753839135169983, 'learning_rate': 4.998721287611319e-05, 'epoch': 0.03}\n",
      "03/26/2024 17:04:50 - INFO - llmtuner.extras.callbacks - {'loss': 0.0644, 'learning_rate': 4.9986e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0644, 'grad_norm': 0.3703654408454895, 'learning_rate': 4.9986346272169994e-05, 'epoch': 0.03}\n",
      "03/26/2024 17:05:02 - INFO - llmtuner.extras.callbacks - {'loss': 0.0791, 'learning_rate': 4.9985e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0791, 'grad_norm': 0.4254704713821411, 'learning_rate': 4.998545126549652e-05, 'epoch': 0.03}\n",
      "03/26/2024 17:05:15 - INFO - llmtuner.extras.callbacks - {'loss': 0.1029, 'learning_rate': 4.9985e-05, 'epoch': 0.03}\n",
      "{'loss': 0.1029, 'grad_norm': 0.3690769672393799, 'learning_rate': 4.998452785711016e-05, 'epoch': 0.03}\n",
      "03/26/2024 17:05:27 - INFO - llmtuner.extras.callbacks - {'loss': 0.0833, 'learning_rate': 4.9984e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0833, 'grad_norm': 0.45518460869789124, 'learning_rate': 4.9983576048060576e-05, 'epoch': 0.03}\n",
      "03/26/2024 17:05:39 - INFO - llmtuner.extras.callbacks - {'loss': 0.0778, 'learning_rate': 4.9983e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0778, 'grad_norm': 0.32395049929618835, 'learning_rate': 4.9982595839429706e-05, 'epoch': 0.04}\n",
      "03/26/2024 17:05:51 - INFO - llmtuner.extras.callbacks - {'loss': 0.0717, 'learning_rate': 4.9982e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0717, 'grad_norm': 0.3143305778503418, 'learning_rate': 4.9981587232331793e-05, 'epoch': 0.04}\n",
      "03/26/2024 17:06:03 - INFO - llmtuner.extras.callbacks - {'loss': 0.0797, 'learning_rate': 4.9981e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0797, 'grad_norm': 0.4976702928543091, 'learning_rate': 4.998055022791336e-05, 'epoch': 0.04}\n",
      "03/26/2024 17:06:15 - INFO - llmtuner.extras.callbacks - {'loss': 0.0553, 'learning_rate': 4.9979e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0553, 'grad_norm': 0.25189054012298584, 'learning_rate': 4.997948482735318e-05, 'epoch': 0.04}\n",
      "03/26/2024 17:06:27 - INFO - llmtuner.extras.callbacks - {'loss': 0.0744, 'learning_rate': 4.9978e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0744, 'grad_norm': 0.4886041581630707, 'learning_rate': 4.9978391031862335e-05, 'epoch': 0.04}\n",
      "03/26/2024 17:06:39 - INFO - llmtuner.extras.callbacks - {'loss': 0.0723, 'learning_rate': 4.9977e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3203] 2024-03-26 17:06:40,056 >> Saving model checkpoint to saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0723, 'grad_norm': 0.4929368495941162, 'learning_rate': 4.997726884268419e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-03-26 17:06:40,889 >> loading configuration file config.json from cache at /home/users/h/huju/.cache/huggingface/hub/models--codellama--CodeLlama-7b-hf/snapshots/7f22f0a5f7991355a2c3867923359ec4ed0b58bf/config.json\n",
      "[INFO|configuration_utils.py:789] 2024-03-26 17:06:40,891 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"codellama/CodeLlama-7b-hf\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 16384,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.39.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32016\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2502] 2024-03-26 17:06:41,103 >> tokenizer config file saved in saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-200/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2511] 2024-03-26 17:06:41,128 >> Special tokens file saved in saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-200/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/26/2024 17:06:53 - INFO - llmtuner.extras.callbacks - {'loss': 0.0733, 'learning_rate': 4.9976e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0733, 'grad_norm': 0.27818310260772705, 'learning_rate': 4.997611826109435e-05, 'epoch': 0.04}\n",
      "03/26/2024 17:07:06 - INFO - llmtuner.extras.callbacks - {'loss': 0.0907, 'learning_rate': 4.9975e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0907, 'grad_norm': 0.33668869733810425, 'learning_rate': 4.997493928840072e-05, 'epoch': 0.04}\n",
      "03/26/2024 17:07:18 - INFO - llmtuner.extras.callbacks - {'loss': 0.0699, 'learning_rate': 4.9974e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0699, 'grad_norm': 0.3030030429363251, 'learning_rate': 4.9973731925943476e-05, 'epoch': 0.04}\n",
      "03/26/2024 17:07:32 - INFO - llmtuner.extras.callbacks - {'loss': 0.0586, 'learning_rate': 4.9972e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0586, 'grad_norm': 0.5249671936035156, 'learning_rate': 4.997249617509507e-05, 'epoch': 0.04}\n",
      "03/26/2024 17:07:44 - INFO - llmtuner.extras.callbacks - {'loss': 0.0485, 'learning_rate': 4.9971e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0485, 'grad_norm': 0.3392108678817749, 'learning_rate': 4.9971232037260215e-05, 'epoch': 0.05}\n",
      "03/26/2024 17:07:57 - INFO - llmtuner.extras.callbacks - {'loss': 0.0977, 'learning_rate': 4.9970e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0977, 'grad_norm': 0.3812776207923889, 'learning_rate': 4.9969939513875886e-05, 'epoch': 0.05}\n",
      "03/26/2024 17:08:09 - INFO - llmtuner.extras.callbacks - {'loss': 0.0546, 'learning_rate': 4.9969e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0546, 'grad_norm': 0.3240008056163788, 'learning_rate': 4.9968618606411335e-05, 'epoch': 0.05}\n",
      "03/26/2024 17:08:21 - INFO - llmtuner.extras.callbacks - {'loss': 0.0550, 'learning_rate': 4.9967e-05, 'epoch': 0.05}\n",
      "{'loss': 0.055, 'grad_norm': 0.3857342600822449, 'learning_rate': 4.996726931636808e-05, 'epoch': 0.05}\n",
      "03/26/2024 17:08:33 - INFO - llmtuner.extras.callbacks - {'loss': 0.0541, 'learning_rate': 4.9966e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0541, 'grad_norm': 0.40020766854286194, 'learning_rate': 4.996589164527991e-05, 'epoch': 0.05}\n",
      "03/26/2024 17:08:45 - INFO - llmtuner.extras.callbacks - {'loss': 0.0625, 'learning_rate': 4.9964e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0625, 'grad_norm': 0.41407036781311035, 'learning_rate': 4.996448559471285e-05, 'epoch': 0.05}\n",
      "03/26/2024 17:08:58 - INFO - llmtuner.extras.callbacks - {'loss': 0.0897, 'learning_rate': 4.9963e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0897, 'grad_norm': 0.39730149507522583, 'learning_rate': 4.99630511662652e-05, 'epoch': 0.05}\n",
      "03/26/2024 17:09:10 - INFO - llmtuner.extras.callbacks - {'loss': 0.0561, 'learning_rate': 4.9962e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0561, 'grad_norm': 0.24270302057266235, 'learning_rate': 4.9961588361567526e-05, 'epoch': 0.05}\n",
      "03/26/2024 17:09:23 - INFO - llmtuner.extras.callbacks - {'loss': 0.0597, 'learning_rate': 4.9960e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0597, 'grad_norm': 0.3720036745071411, 'learning_rate': 4.996009718228264e-05, 'epoch': 0.05}\n",
      "03/26/2024 17:09:35 - INFO - llmtuner.extras.callbacks - {'loss': 0.0614, 'learning_rate': 4.9959e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0614, 'grad_norm': 0.48980337381362915, 'learning_rate': 4.9958577630105604e-05, 'epoch': 0.05}\n",
      "03/26/2024 17:09:47 - INFO - llmtuner.extras.callbacks - {'loss': 0.0792, 'learning_rate': 4.9957e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0792, 'grad_norm': 0.43844670057296753, 'learning_rate': 4.9957029706763745e-05, 'epoch': 0.06}\n",
      "03/26/2024 17:09:59 - INFO - llmtuner.extras.callbacks - {'loss': 0.0712, 'learning_rate': 4.9955e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0712, 'grad_norm': 0.2507949769496918, 'learning_rate': 4.995545341401663e-05, 'epoch': 0.06}\n",
      "03/26/2024 17:10:12 - INFO - llmtuner.extras.callbacks - {'loss': 0.0499, 'learning_rate': 4.9954e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0499, 'grad_norm': 0.5227243900299072, 'learning_rate': 4.995384875365608e-05, 'epoch': 0.06}\n",
      "03/26/2024 17:10:25 - INFO - llmtuner.extras.callbacks - {'loss': 0.0669, 'learning_rate': 4.9952e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0669, 'grad_norm': 0.5457651019096375, 'learning_rate': 4.995221572750618e-05, 'epoch': 0.06}\n",
      "03/26/2024 17:10:37 - INFO - llmtuner.extras.callbacks - {'loss': 0.0453, 'learning_rate': 4.9951e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0453, 'grad_norm': 0.3433312177658081, 'learning_rate': 4.995055433742321e-05, 'epoch': 0.06}\n",
      "03/26/2024 17:10:49 - INFO - llmtuner.extras.callbacks - {'loss': 0.0360, 'learning_rate': 4.9949e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3203] 2024-03-26 17:10:49,988 >> Saving model checkpoint to saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.036, 'grad_norm': 0.28479260206222534, 'learning_rate': 4.994886458529572e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-03-26 17:10:50,806 >> loading configuration file config.json from cache at /home/users/h/huju/.cache/huggingface/hub/models--codellama--CodeLlama-7b-hf/snapshots/7f22f0a5f7991355a2c3867923359ec4ed0b58bf/config.json\n",
      "[INFO|configuration_utils.py:789] 2024-03-26 17:10:50,809 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"codellama/CodeLlama-7b-hf\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 16384,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.39.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32016\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2502] 2024-03-26 17:10:50,957 >> tokenizer config file saved in saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-300/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2511] 2024-03-26 17:10:50,961 >> Special tokens file saved in saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-300/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/26/2024 17:11:03 - INFO - llmtuner.extras.callbacks - {'loss': 0.0543, 'learning_rate': 4.9947e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0543, 'grad_norm': 0.2507052719593048, 'learning_rate': 4.994714647304453e-05, 'epoch': 0.06}\n",
      "03/26/2024 17:11:16 - INFO - llmtuner.extras.callbacks - {'loss': 0.0549, 'learning_rate': 4.9945e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0549, 'grad_norm': 0.33163318037986755, 'learning_rate': 4.9945400002622656e-05, 'epoch': 0.06}\n",
      "03/26/2024 17:11:29 - INFO - llmtuner.extras.callbacks - {'loss': 0.0444, 'learning_rate': 4.9944e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0444, 'grad_norm': 0.3424566090106964, 'learning_rate': 4.994362517601535e-05, 'epoch': 0.06}\n",
      "03/26/2024 17:11:41 - INFO - llmtuner.extras.callbacks - {'loss': 0.0721, 'learning_rate': 4.9942e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0721, 'grad_norm': 0.4164498746395111, 'learning_rate': 4.994182199524013e-05, 'epoch': 0.07}\n",
      "03/26/2024 17:11:54 - INFO - llmtuner.extras.callbacks - {'loss': 0.0536, 'learning_rate': 4.9940e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0536, 'grad_norm': 0.3720856308937073, 'learning_rate': 4.993999046234673e-05, 'epoch': 0.07}\n",
      "03/26/2024 17:12:07 - INFO - llmtuner.extras.callbacks - {'loss': 0.0434, 'learning_rate': 4.9938e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0434, 'grad_norm': 0.28258511424064636, 'learning_rate': 4.9938130579417086e-05, 'epoch': 0.07}\n",
      "03/26/2024 17:12:20 - INFO - llmtuner.extras.callbacks - {'loss': 0.0785, 'learning_rate': 4.9936e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0785, 'grad_norm': 0.29697057604789734, 'learning_rate': 4.99362423485654e-05, 'epoch': 0.07}\n",
      "03/26/2024 17:12:35 - INFO - llmtuner.extras.callbacks - {'loss': 0.0431, 'learning_rate': 4.9934e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0431, 'grad_norm': 0.34608665108680725, 'learning_rate': 4.9934325771938065e-05, 'epoch': 0.07}\n",
      "03/26/2024 17:12:55 - INFO - llmtuner.extras.callbacks - {'loss': 0.0599, 'learning_rate': 4.9932e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0599, 'grad_norm': 0.28364846110343933, 'learning_rate': 4.993238085171373e-05, 'epoch': 0.07}\n",
      "03/26/2024 17:13:14 - INFO - llmtuner.extras.callbacks - {'loss': 0.0464, 'learning_rate': 4.9930e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0464, 'grad_norm': 0.11223696917295456, 'learning_rate': 4.9930407590103234e-05, 'epoch': 0.07}\n",
      "03/26/2024 17:13:33 - INFO - llmtuner.extras.callbacks - {'loss': 0.0590, 'learning_rate': 4.9928e-05, 'epoch': 0.07}\n",
      "{'loss': 0.059, 'grad_norm': 0.4071339964866638, 'learning_rate': 4.992840598934964e-05, 'epoch': 0.07}\n",
      "03/26/2024 17:13:53 - INFO - llmtuner.extras.callbacks - {'loss': 0.0480, 'learning_rate': 4.9926e-05, 'epoch': 0.07}\n",
      "{'loss': 0.048, 'grad_norm': 0.5804802179336548, 'learning_rate': 4.992637605172823e-05, 'epoch': 0.07}\n",
      "03/26/2024 17:14:11 - INFO - llmtuner.extras.callbacks - {'loss': 0.0476, 'learning_rate': 4.9924e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0476, 'grad_norm': 0.5976301431655884, 'learning_rate': 4.992431777954651e-05, 'epoch': 0.07}\n",
      "03/26/2024 17:14:30 - INFO - llmtuner.extras.callbacks - {'loss': 0.0424, 'learning_rate': 4.9922e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0424, 'grad_norm': 0.36969509720802307, 'learning_rate': 4.992223117514416e-05, 'epoch': 0.08}\n",
      "03/26/2024 17:14:50 - INFO - llmtuner.extras.callbacks - {'loss': 0.0443, 'learning_rate': 4.9920e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0443, 'grad_norm': 0.27394211292266846, 'learning_rate': 4.992011624089309e-05, 'epoch': 0.08}\n",
      "03/26/2024 17:15:09 - INFO - llmtuner.extras.callbacks - {'loss': 0.0563, 'learning_rate': 4.9918e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0563, 'grad_norm': 0.5843098163604736, 'learning_rate': 4.991797297919741e-05, 'epoch': 0.08}\n",
      "03/26/2024 17:15:29 - INFO - llmtuner.extras.callbacks - {'loss': 0.0537, 'learning_rate': 4.9916e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0537, 'grad_norm': 0.37866777181625366, 'learning_rate': 4.9915801392493435e-05, 'epoch': 0.08}\n",
      "03/26/2024 17:15:48 - INFO - llmtuner.extras.callbacks - {'loss': 0.0423, 'learning_rate': 4.9914e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0423, 'grad_norm': 0.3686005175113678, 'learning_rate': 4.991360148324967e-05, 'epoch': 0.08}\n",
      "03/26/2024 17:16:08 - INFO - llmtuner.extras.callbacks - {'loss': 0.0508, 'learning_rate': 4.9911e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0508, 'grad_norm': 0.34545090794563293, 'learning_rate': 4.991137325396682e-05, 'epoch': 0.08}\n",
      "03/26/2024 17:16:33 - INFO - llmtuner.extras.callbacks - {'loss': 0.0577, 'learning_rate': 4.9909e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3203] 2024-03-26 17:16:33,676 >> Saving model checkpoint to saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0577, 'grad_norm': 0.4259389042854309, 'learning_rate': 4.9909116707177775e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-03-26 17:16:34,403 >> loading configuration file config.json from cache at /home/users/h/huju/.cache/huggingface/hub/models--codellama--CodeLlama-7b-hf/snapshots/7f22f0a5f7991355a2c3867923359ec4ed0b58bf/config.json\n",
      "[INFO|configuration_utils.py:789] 2024-03-26 17:16:34,405 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"codellama/CodeLlama-7b-hf\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 16384,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.39.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32016\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2502] 2024-03-26 17:16:34,556 >> tokenizer config file saved in saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-400/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2511] 2024-03-26 17:16:34,566 >> Special tokens file saved in saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-400/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/26/2024 17:16:54 - INFO - llmtuner.extras.callbacks - {'loss': 0.0606, 'learning_rate': 4.9907e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0606, 'grad_norm': 0.4246498644351959, 'learning_rate': 4.990683184544762e-05, 'epoch': 0.08}\n",
      "03/26/2024 17:17:14 - INFO - llmtuner.extras.callbacks - {'loss': 0.0494, 'learning_rate': 4.9905e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0494, 'grad_norm': 0.34035274386405945, 'learning_rate': 4.990451867137363e-05, 'epoch': 0.08}\n",
      "03/26/2024 17:17:34 - INFO - llmtuner.extras.callbacks - {'loss': 0.0560, 'learning_rate': 4.9902e-05, 'epoch': 0.08}\n",
      "{'loss': 0.056, 'grad_norm': 0.3890150189399719, 'learning_rate': 4.990217718758526e-05, 'epoch': 0.08}\n",
      "03/26/2024 17:17:53 - INFO - llmtuner.extras.callbacks - {'loss': 0.0953, 'learning_rate': 4.9900e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0953, 'grad_norm': 0.5392023921012878, 'learning_rate': 4.989980739674414e-05, 'epoch': 0.09}\n",
      "03/26/2024 17:18:13 - INFO - llmtuner.extras.callbacks - {'loss': 0.0586, 'learning_rate': 4.9897e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0586, 'grad_norm': 0.2509501576423645, 'learning_rate': 4.989740930154409e-05, 'epoch': 0.09}\n",
      "03/26/2024 17:18:32 - INFO - llmtuner.extras.callbacks - {'loss': 0.0421, 'learning_rate': 4.9895e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0421, 'grad_norm': 0.3845800459384918, 'learning_rate': 4.9894982904711087e-05, 'epoch': 0.09}\n",
      "03/26/2024 17:18:51 - INFO - llmtuner.extras.callbacks - {'loss': 0.0379, 'learning_rate': 4.9893e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0379, 'grad_norm': 0.3609820306301117, 'learning_rate': 4.9892528209003286e-05, 'epoch': 0.09}\n",
      "03/26/2024 17:19:10 - INFO - llmtuner.extras.callbacks - {'loss': 0.0477, 'learning_rate': 4.9890e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0477, 'grad_norm': 0.5285595655441284, 'learning_rate': 4.989004521721104e-05, 'epoch': 0.09}\n",
      "03/26/2024 17:19:29 - INFO - llmtuner.extras.callbacks - {'loss': 0.0496, 'learning_rate': 4.9888e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0496, 'grad_norm': 0.3540617823600769, 'learning_rate': 4.988753393215681e-05, 'epoch': 0.09}\n",
      "03/26/2024 17:19:48 - INFO - llmtuner.extras.callbacks - {'loss': 0.0399, 'learning_rate': 4.9885e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0399, 'grad_norm': 0.2864632308483124, 'learning_rate': 4.9884994356695255e-05, 'epoch': 0.09}\n",
      "03/26/2024 17:20:07 - INFO - llmtuner.extras.callbacks - {'loss': 0.0431, 'learning_rate': 4.9882e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0431, 'grad_norm': 0.685512363910675, 'learning_rate': 4.9882426493713204e-05, 'epoch': 0.09}\n",
      "03/26/2024 17:20:26 - INFO - llmtuner.extras.callbacks - {'loss': 0.0562, 'learning_rate': 4.9880e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0562, 'grad_norm': 0.4638393223285675, 'learning_rate': 4.987983034612961e-05, 'epoch': 0.09}\n",
      "03/26/2024 17:20:45 - INFO - llmtuner.extras.callbacks - {'loss': 0.0438, 'learning_rate': 4.9877e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0438, 'grad_norm': 0.31407126784324646, 'learning_rate': 4.9877205916895586e-05, 'epoch': 0.09}\n",
      "03/26/2024 17:21:05 - INFO - llmtuner.extras.callbacks - {'loss': 0.0391, 'learning_rate': 4.9875e-05, 'epoch': 0.10}\n",
      "{'loss': 0.0391, 'grad_norm': 0.38177192211151123, 'learning_rate': 4.987455320899442e-05, 'epoch': 0.1}\n",
      "03/26/2024 17:21:24 - INFO - llmtuner.extras.callbacks - {'loss': 0.0398, 'learning_rate': 4.9872e-05, 'epoch': 0.10}\n",
      "{'loss': 0.0398, 'grad_norm': 0.45757725834846497, 'learning_rate': 4.987187222544151e-05, 'epoch': 0.1}\n",
      "03/26/2024 17:21:41 - INFO - llmtuner.extras.callbacks - {'loss': 0.0369, 'learning_rate': 4.9869e-05, 'epoch': 0.10}\n",
      "{'loss': 0.0369, 'grad_norm': 0.276865690946579, 'learning_rate': 4.98691629692844e-05, 'epoch': 0.1}\n",
      "03/26/2024 17:21:55 - INFO - llmtuner.extras.callbacks - {'loss': 0.0623, 'learning_rate': 4.9866e-05, 'epoch': 0.10}\n",
      "{'loss': 0.0623, 'grad_norm': 0.4102829694747925, 'learning_rate': 4.986642544360281e-05, 'epoch': 0.1}\n",
      "03/26/2024 17:22:07 - INFO - llmtuner.extras.callbacks - {'loss': 0.0584, 'learning_rate': 4.9864e-05, 'epoch': 0.10}\n",
      "{'loss': 0.0584, 'grad_norm': 0.5693778991699219, 'learning_rate': 4.9863659651508554e-05, 'epoch': 0.1}\n",
      "03/26/2024 17:22:20 - INFO - llmtuner.extras.callbacks - {'loss': 0.0499, 'learning_rate': 4.9861e-05, 'epoch': 0.10}\n",
      "{'loss': 0.0499, 'grad_norm': 0.43686285614967346, 'learning_rate': 4.986086559614559e-05, 'epoch': 0.1}\n",
      "03/26/2024 17:22:32 - INFO - llmtuner.extras.callbacks - {'loss': 0.0327, 'learning_rate': 4.9858e-05, 'epoch': 0.10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3203] 2024-03-26 17:22:32,727 >> Saving model checkpoint to saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0327, 'grad_norm': 0.5034130215644836, 'learning_rate': 4.985804328069e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-03-26 17:22:33,303 >> loading configuration file config.json from cache at /home/users/h/huju/.cache/huggingface/hub/models--codellama--CodeLlama-7b-hf/snapshots/7f22f0a5f7991355a2c3867923359ec4ed0b58bf/config.json\n",
      "[INFO|configuration_utils.py:789] 2024-03-26 17:22:33,305 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"codellama/CodeLlama-7b-hf\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 16384,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.39.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32016\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2502] 2024-03-26 17:22:33,429 >> tokenizer config file saved in saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2511] 2024-03-26 17:22:33,434 >> Special tokens file saved in saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/26/2024 17:22:45 - INFO - llmtuner.extras.callbacks - {'loss': 0.0493, 'learning_rate': 4.9855e-05, 'epoch': 0.10}\n",
      "{'loss': 0.0493, 'grad_norm': 0.49071842432022095, 'learning_rate': 4.9855192708350006e-05, 'epoch': 0.1}\n",
      "03/26/2024 17:22:58 - INFO - llmtuner.extras.callbacks - {'loss': 0.0426, 'learning_rate': 4.9852e-05, 'epoch': 0.10}\n",
      "{'loss': 0.0426, 'grad_norm': 0.2774227559566498, 'learning_rate': 4.985231388236593e-05, 'epoch': 0.1}\n",
      "03/26/2024 17:23:10 - INFO - llmtuner.extras.callbacks - {'loss': 0.0355, 'learning_rate': 4.9849e-05, 'epoch': 0.10}\n",
      "{'loss': 0.0355, 'grad_norm': 0.38814017176628113, 'learning_rate': 4.984940680601022e-05, 'epoch': 0.1}\n",
      "03/26/2024 17:23:22 - INFO - llmtuner.extras.callbacks - {'loss': 0.0735, 'learning_rate': 4.9846e-05, 'epoch': 0.11}\n",
      "{'loss': 0.0735, 'grad_norm': 0.577547013759613, 'learning_rate': 4.9846471482587445e-05, 'epoch': 0.11}\n",
      "03/26/2024 17:23:34 - INFO - llmtuner.extras.callbacks - {'loss': 0.0370, 'learning_rate': 4.9844e-05, 'epoch': 0.11}\n",
      "{'loss': 0.037, 'grad_norm': 0.476088285446167, 'learning_rate': 4.984350791543427e-05, 'epoch': 0.11}\n",
      "03/26/2024 17:23:45 - INFO - llmtuner.extras.callbacks - {'loss': 0.0665, 'learning_rate': 4.9841e-05, 'epoch': 0.11}\n",
      "{'loss': 0.0665, 'grad_norm': 0.4381744861602783, 'learning_rate': 4.9840516107919474e-05, 'epoch': 0.11}\n",
      "03/26/2024 17:23:58 - INFO - llmtuner.extras.callbacks - {'loss': 0.0445, 'learning_rate': 4.9837e-05, 'epoch': 0.11}\n",
      "{'loss': 0.0445, 'grad_norm': 0.30698150396347046, 'learning_rate': 4.983749606344393e-05, 'epoch': 0.11}\n",
      "03/26/2024 17:24:11 - INFO - llmtuner.extras.callbacks - {'loss': 0.0483, 'learning_rate': 4.9834e-05, 'epoch': 0.11}\n",
      "{'loss': 0.0483, 'grad_norm': 0.30573660135269165, 'learning_rate': 4.983444778544061e-05, 'epoch': 0.11}\n",
      "03/26/2024 17:24:23 - INFO - llmtuner.extras.callbacks - {'loss': 0.0440, 'learning_rate': 4.9831e-05, 'epoch': 0.11}\n",
      "{'loss': 0.044, 'grad_norm': 0.3758096396923065, 'learning_rate': 4.983137127737459e-05, 'epoch': 0.11}\n",
      "03/26/2024 17:24:35 - INFO - llmtuner.extras.callbacks - {'loss': 0.0404, 'learning_rate': 4.9828e-05, 'epoch': 0.11}\n",
      "{'loss': 0.0404, 'grad_norm': 0.4607301950454712, 'learning_rate': 4.982826654274303e-05, 'epoch': 0.11}\n",
      "03/26/2024 17:24:48 - INFO - llmtuner.extras.callbacks - {'loss': 0.0610, 'learning_rate': 4.9825e-05, 'epoch': 0.11}\n",
      "{'loss': 0.061, 'grad_norm': 0.34809166193008423, 'learning_rate': 4.9825133585075176e-05, 'epoch': 0.11}\n",
      "03/26/2024 17:25:02 - INFO - llmtuner.extras.callbacks - {'loss': 0.0472, 'learning_rate': 4.9822e-05, 'epoch': 0.11}\n",
      "{'loss': 0.0472, 'grad_norm': 0.38070741295814514, 'learning_rate': 4.982197240793235e-05, 'epoch': 0.11}\n",
      "03/26/2024 17:25:15 - INFO - llmtuner.extras.callbacks - {'loss': 0.0310, 'learning_rate': 4.9819e-05, 'epoch': 0.12}\n",
      "{'loss': 0.031, 'grad_norm': 0.24955275654792786, 'learning_rate': 4.9818783014907954e-05, 'epoch': 0.12}\n",
      "03/26/2024 17:25:28 - INFO - llmtuner.extras.callbacks - {'loss': 0.0568, 'learning_rate': 4.9816e-05, 'epoch': 0.12}\n",
      "{'loss': 0.0568, 'grad_norm': 0.3380296230316162, 'learning_rate': 4.981556540962747e-05, 'epoch': 0.12}\n",
      "03/26/2024 17:25:41 - INFO - llmtuner.extras.callbacks - {'loss': 0.0525, 'learning_rate': 4.9812e-05, 'epoch': 0.12}\n",
      "{'loss': 0.0525, 'grad_norm': 0.37862542271614075, 'learning_rate': 4.9812319595748456e-05, 'epoch': 0.12}\n",
      "03/26/2024 17:25:54 - INFO - llmtuner.extras.callbacks - {'loss': 0.0430, 'learning_rate': 4.9809e-05, 'epoch': 0.12}\n",
      "{'loss': 0.043, 'grad_norm': 0.5260217785835266, 'learning_rate': 4.980904557696051e-05, 'epoch': 0.12}\n",
      "03/26/2024 17:26:09 - INFO - llmtuner.extras.callbacks - {'loss': 0.0398, 'learning_rate': 4.9806e-05, 'epoch': 0.12}\n",
      "{'loss': 0.0398, 'grad_norm': 0.5926563739776611, 'learning_rate': 4.980574335698532e-05, 'epoch': 0.12}\n",
      "03/26/2024 17:26:24 - INFO - llmtuner.extras.callbacks - {'loss': 0.0344, 'learning_rate': 4.9802e-05, 'epoch': 0.12}\n",
      "{'loss': 0.0344, 'grad_norm': 0.20714010298252106, 'learning_rate': 4.980241293957661e-05, 'epoch': 0.12}\n",
      "03/26/2024 17:26:38 - INFO - llmtuner.extras.callbacks - {'loss': 0.0347, 'learning_rate': 4.9799e-05, 'epoch': 0.12}\n",
      "{'loss': 0.0347, 'grad_norm': 0.31424641609191895, 'learning_rate': 4.979905432852018e-05, 'epoch': 0.12}\n",
      "03/26/2024 17:26:55 - INFO - llmtuner.extras.callbacks - {'loss': 0.0513, 'learning_rate': 4.9796e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3203] 2024-03-26 17:26:55,168 >> Saving model checkpoint to saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0513, 'grad_norm': 0.22517167031764984, 'learning_rate': 4.979566752763385e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-03-26 17:26:55,556 >> loading configuration file config.json from cache at /home/users/h/huju/.cache/huggingface/hub/models--codellama--CodeLlama-7b-hf/snapshots/7f22f0a5f7991355a2c3867923359ec4ed0b58bf/config.json\n",
      "[INFO|configuration_utils.py:789] 2024-03-26 17:26:55,558 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"codellama/CodeLlama-7b-hf\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 16384,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.39.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32016\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2502] 2024-03-26 17:26:55,698 >> tokenizer config file saved in saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-600/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2511] 2024-03-26 17:26:55,702 >> Special tokens file saved in saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-600/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/26/2024 17:27:09 - INFO - llmtuner.extras.callbacks - {'loss': 0.0341, 'learning_rate': 4.9792e-05, 'epoch': 0.12}\n",
      "{'loss': 0.0341, 'grad_norm': 0.44336146116256714, 'learning_rate': 4.97922525407675e-05, 'epoch': 0.12}\n",
      "03/26/2024 17:27:24 - INFO - llmtuner.extras.callbacks - {'loss': 0.0373, 'learning_rate': 4.9789e-05, 'epoch': 0.12}\n",
      "{'loss': 0.0373, 'grad_norm': 0.22002580761909485, 'learning_rate': 4.978880937180305e-05, 'epoch': 0.12}\n",
      "03/26/2024 17:27:48 - INFO - llmtuner.extras.callbacks - {'loss': 0.0475, 'learning_rate': 4.9785e-05, 'epoch': 0.13}\n",
      "{'loss': 0.0475, 'grad_norm': 0.31462669372558594, 'learning_rate': 4.978533802465445e-05, 'epoch': 0.13}\n",
      "03/26/2024 17:28:09 - INFO - llmtuner.extras.callbacks - {'loss': 0.0500, 'learning_rate': 4.9782e-05, 'epoch': 0.13}\n",
      "{'loss': 0.05, 'grad_norm': 0.23674771189689636, 'learning_rate': 4.978183850326769e-05, 'epoch': 0.13}\n",
      "03/26/2024 17:28:27 - INFO - llmtuner.extras.callbacks - {'loss': 0.0537, 'learning_rate': 4.9778e-05, 'epoch': 0.13}\n",
      "{'loss': 0.0537, 'grad_norm': 0.6091932654380798, 'learning_rate': 4.977831081162078e-05, 'epoch': 0.13}\n",
      "03/26/2024 17:28:50 - INFO - llmtuner.extras.callbacks - {'loss': 0.0699, 'learning_rate': 4.9775e-05, 'epoch': 0.13}\n",
      "{'loss': 0.0699, 'grad_norm': 0.3434637188911438, 'learning_rate': 4.977475495372376e-05, 'epoch': 0.13}\n",
      "03/26/2024 17:29:07 - INFO - llmtuner.extras.callbacks - {'loss': 0.0383, 'learning_rate': 4.9771e-05, 'epoch': 0.13}\n",
      "{'loss': 0.0383, 'grad_norm': 0.4688769578933716, 'learning_rate': 4.977117093361866e-05, 'epoch': 0.13}\n",
      "03/26/2024 17:29:18 - INFO - llmtuner.extras.callbacks - {'loss': 0.0540, 'learning_rate': 4.9768e-05, 'epoch': 0.13}\n",
      "{'loss': 0.054, 'grad_norm': 0.3802596926689148, 'learning_rate': 4.9767558755379564e-05, 'epoch': 0.13}\n",
      "03/26/2024 17:29:28 - INFO - llmtuner.extras.callbacks - {'loss': 0.0392, 'learning_rate': 4.9764e-05, 'epoch': 0.13}\n",
      "{'loss': 0.0392, 'grad_norm': 0.17826931178569794, 'learning_rate': 4.9763918423112536e-05, 'epoch': 0.13}\n",
      "03/26/2024 17:29:40 - INFO - llmtuner.extras.callbacks - {'loss': 0.0249, 'learning_rate': 4.9760e-05, 'epoch': 0.13}\n",
      "{'loss': 0.0249, 'grad_norm': 0.42483943700790405, 'learning_rate': 4.976024994095565e-05, 'epoch': 0.13}\n",
      "03/26/2024 17:29:50 - INFO - llmtuner.extras.callbacks - {'loss': 0.0534, 'learning_rate': 4.9757e-05, 'epoch': 0.13}\n",
      "{'loss': 0.0534, 'grad_norm': 0.6213780641555786, 'learning_rate': 4.975655331307898e-05, 'epoch': 0.13}\n",
      "03/26/2024 17:29:59 - INFO - llmtuner.extras.callbacks - {'loss': 0.0345, 'learning_rate': 4.9753e-05, 'epoch': 0.13}\n",
      "{'loss': 0.0345, 'grad_norm': 0.31335216760635376, 'learning_rate': 4.9752828543684596e-05, 'epoch': 0.13}\n",
      "03/26/2024 17:30:09 - INFO - llmtuner.extras.callbacks - {'loss': 0.0405, 'learning_rate': 4.9749e-05, 'epoch': 0.14}\n",
      "{'loss': 0.0405, 'grad_norm': 0.30172908306121826, 'learning_rate': 4.9749075637006547e-05, 'epoch': 0.14}\n",
      "03/26/2024 17:30:23 - INFO - llmtuner.extras.callbacks - {'loss': 0.0336, 'learning_rate': 4.9745e-05, 'epoch': 0.14}\n",
      "{'loss': 0.0336, 'grad_norm': 0.340404212474823, 'learning_rate': 4.974529459731089e-05, 'epoch': 0.14}\n",
      "03/26/2024 17:30:38 - INFO - llmtuner.extras.callbacks - {'loss': 0.0325, 'learning_rate': 4.9741e-05, 'epoch': 0.14}\n",
      "{'loss': 0.0325, 'grad_norm': 0.40322989225387573, 'learning_rate': 4.974148542889564e-05, 'epoch': 0.14}\n",
      "03/26/2024 17:30:56 - INFO - llmtuner.extras.callbacks - {'loss': 0.0578, 'learning_rate': 4.9738e-05, 'epoch': 0.14}\n",
      "{'loss': 0.0578, 'grad_norm': 0.3621315360069275, 'learning_rate': 4.9737648136090786e-05, 'epoch': 0.14}\n",
      "03/26/2024 17:31:14 - INFO - llmtuner.extras.callbacks - {'loss': 0.0245, 'learning_rate': 4.9734e-05, 'epoch': 0.14}\n",
      "{'loss': 0.0245, 'grad_norm': 0.43676578998565674, 'learning_rate': 4.973378272325829e-05, 'epoch': 0.14}\n",
      "03/26/2024 17:31:33 - INFO - llmtuner.extras.callbacks - {'loss': 0.0393, 'learning_rate': 4.9730e-05, 'epoch': 0.14}\n",
      "{'loss': 0.0393, 'grad_norm': 0.3439556360244751, 'learning_rate': 4.972988919479211e-05, 'epoch': 0.14}\n",
      "03/26/2024 17:31:56 - INFO - llmtuner.extras.callbacks - {'loss': 0.0245, 'learning_rate': 4.9726e-05, 'epoch': 0.14}\n",
      "{'loss': 0.0245, 'grad_norm': 0.3393357992172241, 'learning_rate': 4.97259675551181e-05, 'epoch': 0.14}\n",
      "03/26/2024 17:32:29 - INFO - llmtuner.extras.callbacks - {'loss': 0.0293, 'learning_rate': 4.9722e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3203] 2024-03-26 17:32:30,019 >> Saving model checkpoint to saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0293, 'grad_norm': 0.2905043363571167, 'learning_rate': 4.9722017808694145e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-03-26 17:32:31,022 >> loading configuration file config.json from cache at /home/users/h/huju/.cache/huggingface/hub/models--codellama--CodeLlama-7b-hf/snapshots/7f22f0a5f7991355a2c3867923359ec4ed0b58bf/config.json\n",
      "[INFO|configuration_utils.py:789] 2024-03-26 17:32:31,025 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"codellama/CodeLlama-7b-hf\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 16384,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.39.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32016\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2502] 2024-03-26 17:32:31,167 >> tokenizer config file saved in saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-700/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2511] 2024-03-26 17:32:31,171 >> Special tokens file saved in saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-700/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/26/2024 17:32:57 - INFO - llmtuner.extras.callbacks - {'loss': 0.0378, 'learning_rate': 4.9718e-05, 'epoch': 0.14}\n",
      "{'loss': 0.0378, 'grad_norm': 0.27574101090431213, 'learning_rate': 4.9718039960010006e-05, 'epoch': 0.14}\n",
      "03/26/2024 17:33:21 - INFO - llmtuner.extras.callbacks - {'loss': 0.0410, 'learning_rate': 4.9714e-05, 'epoch': 0.14}\n",
      "{'loss': 0.041, 'grad_norm': 0.44456297159194946, 'learning_rate': 4.9714034013587444e-05, 'epoch': 0.14}\n",
      "03/26/2024 17:33:46 - INFO - llmtuner.extras.callbacks - {'loss': 0.0485, 'learning_rate': 4.9710e-05, 'epoch': 0.15}\n",
      "{'loss': 0.0485, 'grad_norm': 0.3053988814353943, 'learning_rate': 4.970999997398012e-05, 'epoch': 0.15}\n",
      "03/26/2024 17:34:14 - INFO - llmtuner.extras.callbacks - {'loss': 0.0294, 'learning_rate': 4.9706e-05, 'epoch': 0.15}\n",
      "{'loss': 0.0294, 'grad_norm': 0.4689313769340515, 'learning_rate': 4.970593784577366e-05, 'epoch': 0.15}\n",
      "03/26/2024 17:34:41 - INFO - llmtuner.extras.callbacks - {'loss': 0.0459, 'learning_rate': 4.9702e-05, 'epoch': 0.15}\n",
      "{'loss': 0.0459, 'grad_norm': 0.5038247108459473, 'learning_rate': 4.970184763358562e-05, 'epoch': 0.15}\n",
      "03/26/2024 17:35:05 - INFO - llmtuner.extras.callbacks - {'loss': 0.0405, 'learning_rate': 4.9698e-05, 'epoch': 0.15}\n",
      "{'loss': 0.0405, 'grad_norm': 0.32376882433891296, 'learning_rate': 4.969772934206545e-05, 'epoch': 0.15}\n",
      "03/26/2024 17:35:32 - INFO - llmtuner.extras.callbacks - {'loss': 0.0439, 'learning_rate': 4.9694e-05, 'epoch': 0.15}\n",
      "{'loss': 0.0439, 'grad_norm': 0.4373478889465332, 'learning_rate': 4.9693582975894535e-05, 'epoch': 0.15}\n",
      "03/26/2024 17:35:51 - INFO - llmtuner.extras.callbacks - {'loss': 0.0338, 'learning_rate': 4.9689e-05, 'epoch': 0.15}\n",
      "{'loss': 0.0338, 'grad_norm': 0.20819880068302155, 'learning_rate': 4.968940853978617e-05, 'epoch': 0.15}\n",
      "03/26/2024 17:36:14 - INFO - llmtuner.extras.callbacks - {'loss': 0.0297, 'learning_rate': 4.9685e-05, 'epoch': 0.15}\n",
      "{'loss': 0.0297, 'grad_norm': 0.42606121301651, 'learning_rate': 4.9685206038485585e-05, 'epoch': 0.15}\n",
      "03/26/2024 17:36:40 - INFO - llmtuner.extras.callbacks - {'loss': 0.0448, 'learning_rate': 4.9681e-05, 'epoch': 0.15}\n",
      "{'loss': 0.0448, 'grad_norm': 0.4028058648109436, 'learning_rate': 4.968097547676986e-05, 'epoch': 0.15}\n",
      "03/26/2024 17:37:01 - INFO - llmtuner.extras.callbacks - {'loss': 0.0467, 'learning_rate': 4.9677e-05, 'epoch': 0.15}\n",
      "{'loss': 0.0467, 'grad_norm': 0.25915098190307617, 'learning_rate': 4.967671685944803e-05, 'epoch': 0.15}\n",
      "03/26/2024 17:37:21 - INFO - llmtuner.extras.callbacks - {'loss': 0.0352, 'learning_rate': 4.9672e-05, 'epoch': 0.15}\n",
      "{'loss': 0.0352, 'grad_norm': 0.2713640034198761, 'learning_rate': 4.9672430191360976e-05, 'epoch': 0.15}\n",
      "03/26/2024 17:37:39 - INFO - llmtuner.extras.callbacks - {'loss': 0.0342, 'learning_rate': 4.9668e-05, 'epoch': 0.16}\n",
      "{'loss': 0.0342, 'grad_norm': 0.21000970900058746, 'learning_rate': 4.966811547738148e-05, 'epoch': 0.16}\n",
      "03/26/2024 17:37:59 - INFO - llmtuner.extras.callbacks - {'loss': 0.0491, 'learning_rate': 4.9664e-05, 'epoch': 0.16}\n",
      "{'loss': 0.0491, 'grad_norm': 0.29990890622138977, 'learning_rate': 4.9663772722414215e-05, 'epoch': 0.16}\n",
      "03/26/2024 17:38:23 - INFO - llmtuner.extras.callbacks - {'loss': 0.0278, 'learning_rate': 4.9659e-05, 'epoch': 0.16}\n",
      "{'loss': 0.0278, 'grad_norm': 0.2281709760427475, 'learning_rate': 4.965940193139572e-05, 'epoch': 0.16}\n",
      "03/26/2024 17:38:43 - INFO - llmtuner.extras.callbacks - {'loss': 0.0576, 'learning_rate': 4.9655e-05, 'epoch': 0.16}\n",
      "{'loss': 0.0576, 'grad_norm': 0.6373494267463684, 'learning_rate': 4.965500310929441e-05, 'epoch': 0.16}\n",
      "03/26/2024 17:39:01 - INFO - llmtuner.extras.callbacks - {'loss': 0.0257, 'learning_rate': 4.9651e-05, 'epoch': 0.16}\n",
      "{'loss': 0.0257, 'grad_norm': 0.3622990548610687, 'learning_rate': 4.965057626111054e-05, 'epoch': 0.16}\n",
      "03/26/2024 17:39:13 - INFO - llmtuner.extras.callbacks - {'loss': 0.0393, 'learning_rate': 4.9646e-05, 'epoch': 0.16}\n",
      "{'loss': 0.0393, 'grad_norm': 0.4483863413333893, 'learning_rate': 4.964612139187625e-05, 'epoch': 0.16}\n",
      "03/26/2024 17:39:26 - INFO - llmtuner.extras.callbacks - {'loss': 0.0513, 'learning_rate': 4.9642e-05, 'epoch': 0.16}\n",
      "{'loss': 0.0513, 'grad_norm': 0.3859627842903137, 'learning_rate': 4.964163850665554e-05, 'epoch': 0.16}\n",
      "03/26/2024 17:39:38 - INFO - llmtuner.extras.callbacks - {'loss': 0.0349, 'learning_rate': 4.9637e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3203] 2024-03-26 17:39:39,053 >> Saving model checkpoint to saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0349, 'grad_norm': 0.5122578144073486, 'learning_rate': 4.963712761054422e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-03-26 17:39:39,419 >> loading configuration file config.json from cache at /home/users/h/huju/.cache/huggingface/hub/models--codellama--CodeLlama-7b-hf/snapshots/7f22f0a5f7991355a2c3867923359ec4ed0b58bf/config.json\n",
      "[INFO|configuration_utils.py:789] 2024-03-26 17:39:39,421 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"codellama/CodeLlama-7b-hf\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 16384,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.39.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32016\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2502] 2024-03-26 17:39:39,556 >> tokenizer config file saved in saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-800/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2511] 2024-03-26 17:39:39,561 >> Special tokens file saved in saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-800/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/26/2024 17:39:53 - INFO - llmtuner.extras.callbacks - {'loss': 0.0285, 'learning_rate': 4.9633e-05, 'epoch': 0.16}\n",
      "{'loss': 0.0285, 'grad_norm': 0.5394028425216675, 'learning_rate': 4.963258870866996e-05, 'epoch': 0.16}\n",
      "03/26/2024 17:40:05 - INFO - llmtuner.extras.callbacks - {'loss': 0.0530, 'learning_rate': 4.9628e-05, 'epoch': 0.16}\n",
      "{'loss': 0.053, 'grad_norm': 0.48396140336990356, 'learning_rate': 4.962802180619228e-05, 'epoch': 0.16}\n",
      "03/26/2024 17:40:18 - INFO - llmtuner.extras.callbacks - {'loss': 0.0445, 'learning_rate': 4.9623e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0445, 'grad_norm': 0.2918972074985504, 'learning_rate': 4.9623426908302514e-05, 'epoch': 0.17}\n",
      "03/26/2024 17:40:31 - INFO - llmtuner.extras.callbacks - {'loss': 0.0487, 'learning_rate': 4.9619e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0487, 'grad_norm': 0.45615440607070923, 'learning_rate': 4.961880402022381e-05, 'epoch': 0.17}\n",
      "03/26/2024 17:40:44 - INFO - llmtuner.extras.callbacks - {'loss': 0.0474, 'learning_rate': 4.9614e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0474, 'grad_norm': 0.31015241146087646, 'learning_rate': 4.961415314721115e-05, 'epoch': 0.17}\n",
      "03/26/2024 17:40:57 - INFO - llmtuner.extras.callbacks - {'loss': 0.0519, 'learning_rate': 4.9609e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0519, 'grad_norm': 0.5547966361045837, 'learning_rate': 4.960947429455132e-05, 'epoch': 0.17}\n",
      "03/26/2024 17:41:09 - INFO - llmtuner.extras.callbacks - {'loss': 0.0414, 'learning_rate': 4.9605e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0414, 'grad_norm': 0.3834449052810669, 'learning_rate': 4.960476746756291e-05, 'epoch': 0.17}\n",
      "03/26/2024 17:41:22 - INFO - llmtuner.extras.callbacks - {'loss': 0.0376, 'learning_rate': 4.9600e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0376, 'grad_norm': 0.5246080160140991, 'learning_rate': 4.960003267159632e-05, 'epoch': 0.17}\n",
      "03/26/2024 17:41:34 - INFO - llmtuner.extras.callbacks - {'loss': 0.0227, 'learning_rate': 4.9595e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0227, 'grad_norm': 0.34075459837913513, 'learning_rate': 4.9595269912033725e-05, 'epoch': 0.17}\n",
      "03/26/2024 17:41:47 - INFO - llmtuner.extras.callbacks - {'loss': 0.0344, 'learning_rate': 4.9590e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0344, 'grad_norm': 0.19279856979846954, 'learning_rate': 4.95904791942891e-05, 'epoch': 0.17}\n",
      "03/26/2024 17:42:00 - INFO - llmtuner.extras.callbacks - {'loss': 0.0384, 'learning_rate': 4.9586e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0384, 'grad_norm': 0.10033394396305084, 'learning_rate': 4.9585660523808196e-05, 'epoch': 0.17}\n",
      "03/26/2024 17:42:13 - INFO - llmtuner.extras.callbacks - {'loss': 0.0338, 'learning_rate': 4.9581e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0338, 'grad_norm': 0.5625092387199402, 'learning_rate': 4.958081390606855e-05, 'epoch': 0.18}\n",
      "03/26/2024 17:42:25 - INFO - llmtuner.extras.callbacks - {'loss': 0.0295, 'learning_rate': 4.9576e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0295, 'grad_norm': 0.40825217962265015, 'learning_rate': 4.957593934657945e-05, 'epoch': 0.18}\n",
      "03/26/2024 17:42:38 - INFO - llmtuner.extras.callbacks - {'loss': 0.0584, 'learning_rate': 4.9571e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0584, 'grad_norm': 0.4882171154022217, 'learning_rate': 4.957103685088195e-05, 'epoch': 0.18}\n",
      "03/26/2024 17:42:51 - INFO - llmtuner.extras.callbacks - {'loss': 0.0385, 'learning_rate': 4.9566e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0385, 'grad_norm': 0.5015104413032532, 'learning_rate': 4.9566106424548874e-05, 'epoch': 0.18}\n",
      "03/26/2024 17:43:05 - INFO - llmtuner.extras.callbacks - {'loss': 0.0407, 'learning_rate': 4.9561e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0407, 'grad_norm': 0.46541476249694824, 'learning_rate': 4.956114807318478e-05, 'epoch': 0.18}\n",
      "03/26/2024 17:43:18 - INFO - llmtuner.extras.callbacks - {'loss': 0.0507, 'learning_rate': 4.9556e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0507, 'grad_norm': 0.6168615221977234, 'learning_rate': 4.955616180242597e-05, 'epoch': 0.18}\n",
      "03/26/2024 17:43:31 - INFO - llmtuner.extras.callbacks - {'loss': 0.0448, 'learning_rate': 4.9551e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0448, 'grad_norm': 0.37633007764816284, 'learning_rate': 4.9551147617940495e-05, 'epoch': 0.18}\n",
      "03/26/2024 17:43:43 - INFO - llmtuner.extras.callbacks - {'loss': 0.0544, 'learning_rate': 4.9546e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0544, 'grad_norm': 0.4034840762615204, 'learning_rate': 4.9546105525428134e-05, 'epoch': 0.18}\n",
      "03/26/2024 17:43:56 - INFO - llmtuner.extras.callbacks - {'loss': 0.0259, 'learning_rate': 4.9541e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3203] 2024-03-26 17:43:56,546 >> Saving model checkpoint to saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0259, 'grad_norm': 0.2166648507118225, 'learning_rate': 4.954103553062037e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-03-26 17:43:57,152 >> loading configuration file config.json from cache at /home/users/h/huju/.cache/huggingface/hub/models--codellama--CodeLlama-7b-hf/snapshots/7f22f0a5f7991355a2c3867923359ec4ed0b58bf/config.json\n",
      "[INFO|configuration_utils.py:789] 2024-03-26 17:43:57,154 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"codellama/CodeLlama-7b-hf\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 16384,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.39.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32016\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2502] 2024-03-26 17:43:57,332 >> tokenizer config file saved in saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-900/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2511] 2024-03-26 17:43:57,336 >> Special tokens file saved in saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-900/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/26/2024 17:44:10 - INFO - llmtuner.extras.callbacks - {'loss': 0.0260, 'learning_rate': 4.9536e-05, 'epoch': 0.18}\n",
      "{'loss': 0.026, 'grad_norm': 0.40816137194633484, 'learning_rate': 4.953593763928044e-05, 'epoch': 0.18}\n",
      "03/26/2024 17:44:22 - INFO - llmtuner.extras.callbacks - {'loss': 0.0400, 'learning_rate': 4.9531e-05, 'epoch': 0.19}\n",
      "{'loss': 0.04, 'grad_norm': 0.42890647053718567, 'learning_rate': 4.953081185720324e-05, 'epoch': 0.19}\n",
      "03/26/2024 17:44:35 - INFO - llmtuner.extras.callbacks - {'loss': 0.0315, 'learning_rate': 4.9526e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0315, 'grad_norm': 0.3902718424797058, 'learning_rate': 4.952565819021543e-05, 'epoch': 0.19}\n",
      "03/26/2024 17:44:48 - INFO - llmtuner.extras.callbacks - {'loss': 0.0364, 'learning_rate': 4.9520e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0364, 'grad_norm': 0.28219377994537354, 'learning_rate': 4.952047664417532e-05, 'epoch': 0.19}\n",
      "03/26/2024 17:45:00 - INFO - llmtuner.extras.callbacks - {'loss': 0.0271, 'learning_rate': 4.9515e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0271, 'grad_norm': 0.4795205891132355, 'learning_rate': 4.951526722497294e-05, 'epoch': 0.19}\n",
      "03/26/2024 17:45:17 - INFO - llmtuner.extras.callbacks - {'loss': 0.0291, 'learning_rate': 4.9510e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0291, 'grad_norm': 0.4217020571231842, 'learning_rate': 4.9510029938529986e-05, 'epoch': 0.19}\n",
      "03/26/2024 17:45:31 - INFO - llmtuner.extras.callbacks - {'loss': 0.0213, 'learning_rate': 4.9505e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0213, 'grad_norm': 0.2835310697555542, 'learning_rate': 4.950476479079984e-05, 'epoch': 0.19}\n",
      "03/26/2024 17:45:44 - INFO - llmtuner.extras.callbacks - {'loss': 0.0342, 'learning_rate': 4.9499e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0342, 'grad_norm': 0.3807777166366577, 'learning_rate': 4.9499471787767546e-05, 'epoch': 0.19}\n",
      "03/26/2024 17:45:56 - INFO - llmtuner.extras.callbacks - {'loss': 0.0521, 'learning_rate': 4.9494e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0521, 'grad_norm': 0.3919239938259125, 'learning_rate': 4.9494150935449846e-05, 'epoch': 0.19}\n",
      "03/26/2024 17:46:09 - INFO - llmtuner.extras.callbacks - {'loss': 0.0332, 'learning_rate': 4.9489e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0332, 'grad_norm': 0.326018363237381, 'learning_rate': 4.9488802239895084e-05, 'epoch': 0.19}\n",
      "03/26/2024 17:46:23 - INFO - llmtuner.extras.callbacks - {'loss': 0.0407, 'learning_rate': 4.9483e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0407, 'grad_norm': 0.680927038192749, 'learning_rate': 4.948342570718329e-05, 'epoch': 0.19}\n",
      "03/26/2024 17:46:37 - INFO - llmtuner.extras.callbacks - {'loss': 0.0249, 'learning_rate': 4.9478e-05, 'epoch': 0.20}\n",
      "{'loss': 0.0249, 'grad_norm': 0.21699802577495575, 'learning_rate': 4.947802134342614e-05, 'epoch': 0.2}\n",
      "03/26/2024 17:46:50 - INFO - llmtuner.extras.callbacks - {'loss': 0.0440, 'learning_rate': 4.9473e-05, 'epoch': 0.20}\n",
      "{'loss': 0.044, 'grad_norm': 0.35320281982421875, 'learning_rate': 4.947258915476693e-05, 'epoch': 0.2}\n",
      "03/26/2024 17:47:03 - INFO - llmtuner.extras.callbacks - {'loss': 0.0527, 'learning_rate': 4.9467e-05, 'epoch': 0.20}\n",
      "{'loss': 0.0527, 'grad_norm': 0.32082492113113403, 'learning_rate': 4.946712914738059e-05, 'epoch': 0.2}\n",
      "03/26/2024 17:47:17 - INFO - llmtuner.extras.callbacks - {'loss': 0.0250, 'learning_rate': 4.9462e-05, 'epoch': 0.20}\n",
      "{'loss': 0.025, 'grad_norm': 0.2717908024787903, 'learning_rate': 4.946164132747367e-05, 'epoch': 0.2}\n",
      "03/26/2024 17:47:29 - INFO - llmtuner.extras.callbacks - {'loss': 0.0243, 'learning_rate': 4.9456e-05, 'epoch': 0.20}\n",
      "{'loss': 0.0243, 'grad_norm': 0.3019583225250244, 'learning_rate': 4.945612570128435e-05, 'epoch': 0.2}\n",
      "03/26/2024 17:47:44 - INFO - llmtuner.extras.callbacks - {'loss': 0.0290, 'learning_rate': 4.9451e-05, 'epoch': 0.20}\n",
      "{'loss': 0.029, 'grad_norm': 0.19911468029022217, 'learning_rate': 4.9450582275082414e-05, 'epoch': 0.2}\n",
      "03/26/2024 17:47:57 - INFO - llmtuner.extras.callbacks - {'loss': 0.0379, 'learning_rate': 4.9445e-05, 'epoch': 0.20}\n",
      "{'loss': 0.0379, 'grad_norm': 0.25974953174591064, 'learning_rate': 4.944501105516922e-05, 'epoch': 0.2}\n",
      "03/26/2024 17:48:10 - INFO - llmtuner.extras.callbacks - {'loss': 0.0289, 'learning_rate': 4.9439e-05, 'epoch': 0.20}\n",
      "{'loss': 0.0289, 'grad_norm': 0.1976402997970581, 'learning_rate': 4.943941204787775e-05, 'epoch': 0.2}\n",
      "03/26/2024 17:48:24 - INFO - llmtuner.extras.callbacks - {'loss': 0.0474, 'learning_rate': 4.9434e-05, 'epoch': 0.20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3203] 2024-03-26 17:48:24,873 >> Saving model checkpoint to saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0474, 'grad_norm': 0.5192205905914307, 'learning_rate': 4.943378525957258e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-03-26 17:48:25,589 >> loading configuration file config.json from cache at /home/users/h/huju/.cache/huggingface/hub/models--codellama--CodeLlama-7b-hf/snapshots/7f22f0a5f7991355a2c3867923359ec4ed0b58bf/config.json\n",
      "[INFO|configuration_utils.py:789] 2024-03-26 17:48:25,592 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"codellama/CodeLlama-7b-hf\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 16384,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.39.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32016\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2502] 2024-03-26 17:48:25,736 >> tokenizer config file saved in saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-1000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2511] 2024-03-26 17:48:25,749 >> Special tokens file saved in saves/Custom/lora/train_2024-03-26-16-50-46/checkpoint-1000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/26/2024 17:48:41 - INFO - llmtuner.extras.callbacks - {'loss': 0.0423, 'learning_rate': 4.9428e-05, 'epoch': 0.20}\n",
      "{'loss': 0.0423, 'grad_norm': 0.3076087236404419, 'learning_rate': 4.942813069664983e-05, 'epoch': 0.2}\n",
      "03/26/2024 17:48:54 - INFO - llmtuner.extras.callbacks - {'loss': 0.0458, 'learning_rate': 4.9422e-05, 'epoch': 0.21}\n",
      "{'loss': 0.0458, 'grad_norm': 0.4883386194705963, 'learning_rate': 4.942244836553721e-05, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2231] 2024-03-26 17:49:00,792 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/26/2024 17:49:00 - INFO - llmtuner.extras.callbacks - {'loss': 0.0000, 'learning_rate': 0.0000e+00, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3203] 2024-03-26 17:49:00,802 >> Saving model checkpoint to saves/Custom/lora/train_2024-03-26-16-50-46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 3047.2776, 'train_samples_per_second': 77.358, 'train_steps_per_second': 4.835, 'train_loss': 0.07740363564062495, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-03-26 17:49:01,191 >> loading configuration file config.json from cache at /home/users/h/huju/.cache/huggingface/hub/models--codellama--CodeLlama-7b-hf/snapshots/7f22f0a5f7991355a2c3867923359ec4ed0b58bf/config.json\n",
      "[INFO|configuration_utils.py:789] 2024-03-26 17:49:01,194 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"codellama/CodeLlama-7b-hf\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 16384,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.39.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32016\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2502] 2024-03-26 17:49:01,610 >> tokenizer config file saved in saves/Custom/lora/train_2024-03-26-16-50-46/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2511] 2024-03-26 17:49:01,679 >> Special tokens file saved in saves/Custom/lora/train_2024-03-26-16-50-46/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.21\n",
      "  train_loss               =     0.0774\n",
      "  train_runtime            = 0:50:47.27\n",
      "  train_samples_per_second =     77.358\n",
      "  train_steps_per_second   =      4.835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modelcard.py:450] 2024-03-26 17:49:02,048 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n"
     ]
    }
   ],
   "source": [
    "from llmtuner import create_ui\n",
    "\n",
    "create_ui().queue().launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgR3UFhB0Ifq"
   },
   "source": [
    "## Fine-tune model via Command Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "18e891e5c54048a29b56f46ade947b92",
      "e945c0ff23ed405ab003fbb3bc128799",
      "392bf66717c84ca4a67fa2b63631e705",
      "c08eb3b86c644f648da1d7b5370466fc",
      "1837d6e66f624fb2a865cada3c20083d",
      "02f447d7943b49fb9b860445f5a5d5cf",
      "13c2a6e951f74f5f90b0d84aa5eb06d4",
      "b491a63d00c14c64a98a9be4ff6a6349",
      "554543172a8f42629b8fc01313fa2fd9",
      "721f5318688e449ca3d9d43ecbe9451b",
      "6032c6dd0cc84498a8779492034a0564",
      "128a66c05a9e48a195b9f842971935c0",
      "03803cba8e7640cba253c4a09dcf4961",
      "22da0001b67c457589ed4a5b9a41b20d",
      "24dc94877a96465abaa7200bfbab749d",
      "e4c6bb9c97764e0a979c7247ac93c3fa",
      "d03d0201399f43068e9ac9f979805c7f",
      "81b2131395914c19ba491985fa8e01e1",
      "ca7dd8105a5544bf81831fa864f7975c",
      "093800f206c547fe941aeb3922f03695",
      "da9e68d589e345cca595cecb1d0e7996",
      "119a55cb4316419d82b824fd6d1e3cc3",
      "d205bd683425483abdd970d6a4ecbe24",
      "7f1e958f89e747799b020921f2d33e75",
      "0569943b210a4e9a918d3f0be630f1df",
      "0a00d77bcbc74b04bc375a854701f92f",
      "4f1afb920d364765afb03c38615c94ce",
      "43986f9e13c0407c8a8e211569b1dc85",
      "9dd4ce468c77496e997d54d40ae9479c",
      "2112a54c827f4d048e596058effbb660",
      "bf36698e9fdb4ebc9557dc2aa7095c6b",
      "d0c0c57b40854d2f940aff178fd44908",
      "30664764c59e4b7895be3075e479cdad",
      "7878d5b1a5404df5b0f227088155e754",
      "abf6c990b29e4e03bc7ebd4b8a97137c",
      "97aac7dd3d1749bebb33c0e8fff3d113",
      "b540dea4a46d4c39bdac9980bff70792",
      "bfd01522a6874ec3933143acf290b6e4",
      "66b0f1f7e9fd484d816a397483ecaace",
      "833be6f72a28451bb5f9ca1659c28925",
      "9804e61cd770426fa3a9351c476e0339",
      "0b1a6ed426ed41f0b72cda3d74992ed9",
      "1d0c2f556975480d98889724a1b54324",
      "7363b9307d144353a165de3cb2320043",
      "7e72fa317d6e401d8e1e403d833b6c0f",
      "4b10a7dbe085446a94d3ab3762ee16e4",
      "439e867ccc8b4260b51778f12190d168",
      "d4269a09d2bd49be96faa8c706ad86ec",
      "7602853a84424a93ab04fb9f300d04ab",
      "547d15abbe1243e5a21f71c292bc1457",
      "c803604b47bb4b9197cfc16dc0d61725",
      "b5966cf051f544ddbe502d0b0c698677",
      "a04d61033d7042adae9deacad48ba267",
      "e8da4d8db24541c694a4456dab99712e",
      "e7628413721445919ecbf674f747b91c",
      "e7a730f7e6ff446fae05c52f022161ee",
      "6f726bea48d54f41952fe0a64db948ac",
      "cb24a2b941284c00a59c60aa521b67fd",
      "0d906b908be04f82bd5d9324fcf4a734",
      "b001f63c495346aaabbd750ec07d5ef4",
      "0e37aea1f0af438699f62b322cfb60e5",
      "34e7f3d5e9bb4c279a58e39a457b8825",
      "3d17e37c7ba64b7d84f4fe4586761a9e",
      "999f31445d7e42afba2d504f1f02a2f5",
      "4148233d01014bbbaea6173f998ffbe3",
      "bdd284f73de046e29dfc10378a6639d3",
      "24008a18243a4f25a0ec1fd81f510503",
      "378463ca76cd4dbcbc4ce39a3f38373d",
      "aeadef38e6c24751aac9a109dc4f8d24",
      "734376de3bc6425b81e30804f29a60a9",
      "bcd1efe0682d46dba2f37224b23b479f",
      "1b813a62b30d4ceea1f6bc4b3383454f",
      "5f4ad5b09e2e441685aa38b42d0b2815",
      "82b8d24eb5ad405394bf49ee1e48475b",
      "474b504682d44fc7a38ff6b6fe537990",
      "7524a8bcffed4f9099a70e29a5f6d136",
      "7e4309f5c2cf4e699de5359b1b2d2ae9"
     ]
    },
    "id": "CS0Qk5OR0i4Q",
    "outputId": "e55834cb-0d94-48f5-b062-f1501282379e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/02/2024 11:41:21 - WARNING - llmtuner.hparams.parser - `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:llmtuner.hparams.parser:`ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/02/2024 11:41:21 - INFO - llmtuner.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, compute dtype: torch.float16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llmtuner.hparams.parser:Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, compute dtype: torch.float16\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "[INFO|tokenization_utils_base.py:2046] 2024-03-02 11:41:23,197 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen1.5-0.5B-Chat/snapshots/6c705984bb8b5591dd4e1a9e66e1a127965fd08d/vocab.json\n",
      "[INFO|tokenization_utils_base.py:2046] 2024-03-02 11:41:23,198 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen1.5-0.5B-Chat/snapshots/6c705984bb8b5591dd4e1a9e66e1a127965fd08d/merges.txt\n",
      "[INFO|tokenization_utils_base.py:2046] 2024-03-02 11:41:23,201 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2046] 2024-03-02 11:41:23,203 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2046] 2024-03-02 11:41:23,204 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen1.5-0.5B-Chat/snapshots/6c705984bb8b5591dd4e1a9e66e1a127965fd08d/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2046] 2024-03-02 11:41:23,205 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen1.5-0.5B-Chat/snapshots/6c705984bb8b5591dd4e1a9e66e1a127965fd08d/tokenizer.json\n",
      "[WARNING|logging.py:314] 2024-03-02 11:41:23,497 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/02/2024 11:41:23 - INFO - llmtuner.data.template - Replace eos token: <|im_end|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llmtuner.data.template:Replace eos token: <|im_end|>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/02/2024 11:41:23 - INFO - llmtuner.data.loader - Loading dataset identity.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llmtuner.data.loader:Loading dataset identity.json...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e891e5c54048a29b56f46ade947b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128a66c05a9e48a195b9f842971935c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting format of dataset:   0%|          | 0/91 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/02/2024 11:41:23 - INFO - llmtuner.data.loader - Loading dataset alpaca_gpt4_data_en.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llmtuner.data.loader:Loading dataset alpaca_gpt4_data_en.json...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d205bd683425483abdd970d6a4ecbe24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7878d5b1a5404df5b0f227088155e754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting format of dataset:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/02/2024 11:41:24 - INFO - llmtuner.data.loader - Loading dataset alpaca_gpt4_data_zh.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llmtuner.data.loader:Loading dataset alpaca_gpt4_data_zh.json...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e72fa317d6e401d8e1e403d833b6c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a730f7e6ff446fae05c52f022161ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting format of dataset:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24008a18243a4f25a0ec1fd81f510503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1091 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:728] 2024-03-02 11:41:36,066 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen1.5-0.5B-Chat/snapshots/6c705984bb8b5591dd4e1a9e66e1a127965fd08d/config.json\n",
      "[INFO|configuration_utils.py:791] 2024-03-02 11:41:36,070 >> Model config Qwen2Config {\n",
      "  \"_name_or_path\": \"Qwen/Qwen1.5-0.5B-Chat\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2816,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 21,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_key_value_heads\": 16,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.38.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3257] 2024-03-02 11:41:36,119 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen1.5-0.5B-Chat/snapshots/6c705984bb8b5591dd4e1a9e66e1a127965fd08d/model.safetensors\n",
      "[INFO|modeling_utils.py:1400] 2024-03-02 11:41:36,134 >> Instantiating Qwen2ForCausalLM model under default dtype torch.float16.\n",
      "[INFO|configuration_utils.py:845] 2024-03-02 11:41:36,140 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids:\n",
      "[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 6023, 151645, 198, 151644, 77091, 198, 9707, 0, 358, 1079, 19122, 11, 458, 15235, 17847, 7881, 553, 40809, 13, 2585, 646, 358, 7789, 498, 3351, 30, 151645]\n",
      "inputs:\n",
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "hi<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hello! I am NAME, an AI assistant developed by AUTHOR. How can I assist you today?<|im_end|>\n",
      "label_ids:\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 9707, 0, 358, 1079, 19122, 11, 458, 15235, 17847, 7881, 553, 40809, 13, 2585, 646, 358, 7789, 498, 3351, 30, 151645]\n",
      "labels:\n",
      "Hello! I am NAME, an AI assistant developed by AUTHOR. How can I assist you today?<|im_end|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:3992] 2024-03-02 11:41:38,955 >> All model checkpoint weights were used when initializing Qwen2ForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4000] 2024-03-02 11:41:38,957 >> All the weights of Qwen2ForCausalLM were initialized from the model checkpoint at Qwen/Qwen1.5-0.5B-Chat.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:800] 2024-03-02 11:41:39,032 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen1.5-0.5B-Chat/snapshots/6c705984bb8b5591dd4e1a9e66e1a127965fd08d/generation_config.json\n",
      "[INFO|configuration_utils.py:845] 2024-03-02 11:41:39,033 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    151645,\n",
      "    151643\n",
      "  ],\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"repetition_penalty\": 1.1,\n",
      "  \"top_p\": 0.8\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/02/2024 11:41:39 - INFO - llmtuner.model.patcher - Gradient checkpointing enabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llmtuner.model.patcher:Gradient checkpointing enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/02/2024 11:41:39 - INFO - llmtuner.model.adapter - Fine-tuning method: LoRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llmtuner.model.adapter:Fine-tuning method: LoRA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/02/2024 11:41:39 - INFO - llmtuner.model.utils - Found linear modules: up_proj,gate_proj,v_proj,down_proj,q_proj,k_proj,o_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llmtuner.model.utils:Found linear modules: up_proj,gate_proj,v_proj,down_proj,q_proj,k_proj,o_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/02/2024 11:41:39 - INFO - llmtuner.model.loader - trainable params: 3784704 || all params: 467772416 || trainable%: 0.8091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llmtuner.model.loader:trainable params: 3784704 || all params: 467772416 || trainable%: 0.8091\n",
      "[INFO|trainer.py:601] 2024-03-02 11:41:39,509 >> Using auto half precision backend\n",
      "[INFO|trainer.py:1812] 2024-03-02 11:41:39,956 >> ***** Running training *****\n",
      "[INFO|trainer.py:1813] 2024-03-02 11:41:39,960 >>   Num examples = 1,091\n",
      "[INFO|trainer.py:1814] 2024-03-02 11:41:39,962 >>   Num Epochs = 5\n",
      "[INFO|trainer.py:1815] 2024-03-02 11:41:39,964 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1818] 2024-03-02 11:41:39,967 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "[INFO|trainer.py:1819] 2024-03-02 11:41:39,972 >>   Gradient Accumulation steps = 4\n",
      "[INFO|trainer.py:1820] 2024-03-02 11:41:39,976 >>   Total optimization steps = 340\n",
      "[INFO|trainer.py:1821] 2024-03-02 11:41:39,989 >>   Number of trainable parameters = 3,784,704\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='340' max='340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [340/340 10:26, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.894800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.747500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.691200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.739900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.748100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.707500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.620200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.694400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.643300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.590500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.697900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.594400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.607100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.699000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.626500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.583100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.535800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.584000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.503400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.576700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.580400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.594100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.485600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.532100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.576400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.504300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.480700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.527600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.485500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.470300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.544500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.480300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.528200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.517800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3067] 2024-03-02 11:44:40,127 >> Saving model checkpoint to test_identity/tmp-checkpoint-100\n",
      "[INFO|configuration_utils.py:728] 2024-03-02 11:44:40,462 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen1.5-0.5B-Chat/snapshots/6c705984bb8b5591dd4e1a9e66e1a127965fd08d/config.json\n",
      "[INFO|configuration_utils.py:791] 2024-03-02 11:44:40,464 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2816,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 21,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_key_value_heads\": 16,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.38.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2459] 2024-03-02 11:44:40,516 >> tokenizer config file saved in test_identity/tmp-checkpoint-100/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2468] 2024-03-02 11:44:40,517 >> Special tokens file saved in test_identity/tmp-checkpoint-100/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2519] 2024-03-02 11:44:40,520 >> added tokens file saved in test_identity/tmp-checkpoint-100/added_tokens.json\n",
      "[INFO|trainer.py:3067] 2024-03-02 11:47:49,872 >> Saving model checkpoint to test_identity/tmp-checkpoint-200\n",
      "[INFO|configuration_utils.py:728] 2024-03-02 11:47:50,028 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen1.5-0.5B-Chat/snapshots/6c705984bb8b5591dd4e1a9e66e1a127965fd08d/config.json\n",
      "[INFO|configuration_utils.py:791] 2024-03-02 11:47:50,031 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2816,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 21,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_key_value_heads\": 16,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.38.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2459] 2024-03-02 11:47:50,108 >> tokenizer config file saved in test_identity/tmp-checkpoint-200/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2468] 2024-03-02 11:47:50,114 >> Special tokens file saved in test_identity/tmp-checkpoint-200/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2519] 2024-03-02 11:47:50,116 >> added tokens file saved in test_identity/tmp-checkpoint-200/added_tokens.json\n",
      "[INFO|trainer.py:3067] 2024-03-02 11:50:54,040 >> Saving model checkpoint to test_identity/tmp-checkpoint-300\n",
      "[INFO|configuration_utils.py:728] 2024-03-02 11:50:54,368 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen1.5-0.5B-Chat/snapshots/6c705984bb8b5591dd4e1a9e66e1a127965fd08d/config.json\n",
      "[INFO|configuration_utils.py:791] 2024-03-02 11:50:54,371 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2816,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 21,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_key_value_heads\": 16,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.38.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2459] 2024-03-02 11:50:54,452 >> tokenizer config file saved in test_identity/tmp-checkpoint-300/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2468] 2024-03-02 11:50:54,456 >> Special tokens file saved in test_identity/tmp-checkpoint-300/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2519] 2024-03-02 11:50:54,459 >> added tokens file saved in test_identity/tmp-checkpoint-300/added_tokens.json\n",
      "[INFO|trainer.py:2067] 2024-03-02 11:52:09,548 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:3067] 2024-03-02 11:52:09,556 >> Saving model checkpoint to test_identity\n",
      "[INFO|configuration_utils.py:728] 2024-03-02 11:52:09,703 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen1.5-0.5B-Chat/snapshots/6c705984bb8b5591dd4e1a9e66e1a127965fd08d/config.json\n",
      "[INFO|configuration_utils.py:791] 2024-03-02 11:52:09,706 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2816,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 21,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_key_value_heads\": 16,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.38.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2459] 2024-03-02 11:52:09,786 >> tokenizer config file saved in test_identity/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2468] 2024-03-02 11:52:09,792 >> Special tokens file saved in test_identity/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2519] 2024-03-02 11:52:09,794 >> added tokens file saved in test_identity/added_tokens.json\n",
      "[INFO|modelcard.py:450] 2024-03-02 11:52:10,367 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       4.98\n",
      "  total_flos               =  2579190GF\n",
      "  train_loss               =     1.5998\n",
      "  train_runtime            = 0:10:29.55\n",
      "  train_samples_per_second =      8.665\n",
      "  train_steps_per_second   =       0.54\n"
     ]
    }
   ],
   "source": [
    "from llmtuner import run_exp\n",
    "run_exp(dict(\n",
    "  stage=\"sft\",\n",
    "  do_train=True,\n",
    "  model_name_or_path=\"Qwen/Qwen1.5-0.5B-Chat\",\n",
    "  dataset=\"identity,alpaca_gpt4_en,alpaca_gpt4_zh\",\n",
    "  template=\"qwen\",\n",
    "  finetuning_type=\"lora\",\n",
    "  lora_target=\"all\",\n",
    "  output_dir=\"test_identity\",\n",
    "  per_device_train_batch_size=4,\n",
    "  gradient_accumulation_steps=4,\n",
    "  lr_scheduler_type=\"cosine\",\n",
    "  logging_steps=10,\n",
    "  save_steps=100,\n",
    "  learning_rate=1e-4,\n",
    "  num_train_epochs=5.0,\n",
    "  max_samples=500,\n",
    "  max_grad_norm=1.0,\n",
    "  fp16=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVNaC-xS5N40"
   },
   "source": [
    "### Infer the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oh8H9A_25SF9",
    "outputId": "6730e9db-584a-4485-8b3b-c596749df84a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:2046] 2024-03-02 12:03:09,835 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen1.5-0.5B-Chat/snapshots/6c705984bb8b5591dd4e1a9e66e1a127965fd08d/vocab.json\n",
      "[INFO|tokenization_utils_base.py:2046] 2024-03-02 12:03:09,837 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen1.5-0.5B-Chat/snapshots/6c705984bb8b5591dd4e1a9e66e1a127965fd08d/merges.txt\n",
      "[INFO|tokenization_utils_base.py:2046] 2024-03-02 12:03:09,839 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2046] 2024-03-02 12:03:09,841 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2046] 2024-03-02 12:03:09,843 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen1.5-0.5B-Chat/snapshots/6c705984bb8b5591dd4e1a9e66e1a127965fd08d/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2046] 2024-03-02 12:03:09,845 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen1.5-0.5B-Chat/snapshots/6c705984bb8b5591dd4e1a9e66e1a127965fd08d/tokenizer.json\n",
      "[WARNING|logging.py:314] 2024-03-02 12:03:10,117 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|configuration_utils.py:728] 2024-03-02 12:03:10,188 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen1.5-0.5B-Chat/snapshots/6c705984bb8b5591dd4e1a9e66e1a127965fd08d/config.json\n",
      "[INFO|configuration_utils.py:791] 2024-03-02 12:03:10,191 >> Model config Qwen2Config {\n",
      "  \"_name_or_path\": \"Qwen/Qwen1.5-0.5B-Chat\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2816,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 21,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_key_value_heads\": 16,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.38.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3257] 2024-03-02 12:03:10,196 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen1.5-0.5B-Chat/snapshots/6c705984bb8b5591dd4e1a9e66e1a127965fd08d/model.safetensors\n",
      "[INFO|modeling_utils.py:1400] 2024-03-02 12:03:10,216 >> Instantiating Qwen2ForCausalLM model under default dtype torch.float16.\n",
      "[INFO|configuration_utils.py:845] 2024-03-02 12:03:10,221 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3992] 2024-03-02 12:03:12,983 >> All model checkpoint weights were used when initializing Qwen2ForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4000] 2024-03-02 12:03:12,984 >> All the weights of Qwen2ForCausalLM were initialized from the model checkpoint at Qwen/Qwen1.5-0.5B-Chat.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:800] 2024-03-02 12:03:13,059 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen1.5-0.5B-Chat/snapshots/6c705984bb8b5591dd4e1a9e66e1a127965fd08d/generation_config.json\n",
      "[INFO|configuration_utils.py:845] 2024-03-02 12:03:13,061 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    151645,\n",
      "    151643\n",
      "  ],\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"repetition_penalty\": 1.1,\n",
      "  \"top_p\": 0.8\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/02/2024 12:03:13 - INFO - llmtuner.model.adapter - Fine-tuning method: LoRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llmtuner.model.adapter:Fine-tuning method: LoRA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/02/2024 12:03:14 - INFO - llmtuner.model.adapter - Merged 1 adapter(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llmtuner.model.adapter:Merged 1 adapter(s).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/02/2024 12:03:14 - INFO - llmtuner.model.adapter - Loaded adapter(s): test_identity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llmtuner.model.adapter:Loaded adapter(s): test_identity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/02/2024 12:03:14 - INFO - llmtuner.model.loader - all params: 463987712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llmtuner.model.loader:all params: 463987712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/02/2024 12:03:14 - INFO - llmtuner.data.template - Replace eos token: <|im_end|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llmtuner.data.template:Replace eos token: <|im_end|>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: hi\n",
      "Assistant: Hello! How can I help you today?\n",
      "\n",
      "User: who are you\n",
      "Assistant: I am NAME, an AI assistant developed by AUTHOR. I am here to help you with your queries and provide you with the best possible responses.\n",
      "\n",
      "User: give three tips for staying healthy\n",
      "Assistant: 1. Stay hydrated: Drink plenty of water throughout the day to stay hydrated and keep your body functioning at its best.\n",
      "2. Exercise regularly: Exercise is one of the best ways to stay healthy. Aim for at least 30 minutes of moderate-intensity exercise most days of the week.\n",
      "3. Eat a healthy diet: Eating a balanced and nutritious diet is crucial for maintaining good health. Focus on whole, unprocessed foods, plenty of fruits, vegetables, and lean proteins.\n",
      "\n",
      "User: exit\n"
     ]
    }
   ],
   "source": [
    "from llmtuner import ChatModel\n",
    "chat_model = ChatModel(dict(\n",
    "  model_name_or_path=\"Qwen/Qwen1.5-0.5B-Chat\",\n",
    "  adapter_name_or_path=\"test_identity\",\n",
    "  finetuning_type=\"lora\",\n",
    "  template=\"qwen\",\n",
    "))\n",
    "messages = []\n",
    "while True:\n",
    "  query = input(\"\\nUser: \")\n",
    "  if query.strip() == \"exit\":\n",
    "    break\n",
    "  if query.strip() == \"clear\":\n",
    "    messages = []\n",
    "    continue\n",
    "\n",
    "  messages.append({\"role\": \"user\", \"content\": query})\n",
    "  print(\"Assistant: \", end=\"\", flush=True)\n",
    "  response = \"\"\n",
    "  for new_text in chat_model.stream_chat(messages):\n",
    "    print(new_text, end=\"\", flush=True)\n",
    "    response += new_text\n",
    "  print()\n",
    "  messages.append({\"role\": \"assistant\", \"content\": response})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flmc2i3Z7Bl7"
   },
   "source": [
    "### Merge LoRA weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "1beb7d33abd741abbc2972bb48b4b9bb",
      "23d3a4d7f87245ae97859d77c01ef633",
      "e58d8f51de494c34ae485289b23f90c9",
      "a0f47c5484d6461e8f11398b279f1d9a",
      "d9ef53356ff744849e7cb4c8e610bbea",
      "a7f05924d910420c884464799a623a87",
      "159755c6de394e7d9c5a25907dc153b5",
      "64181e96c6db484c8bcd9c5e5f9c4421",
      "806b6e6df1a64a67b547e542f1c3d4f9",
      "7f1512d7f38740548588d12d46e9a438",
      "195bfaa83de043fd97f9b5f1c79e44a1",
      "2bde6ae496a04435b40e0760af81f1a6",
      "f4c5e9c5f07f4778877143f4bcad4604",
      "eb890d67981944b48e573e8c6fc25853",
      "1a13f097ad494efbbb09561c3db5d54a",
      "0633218a783f400398d1eeb270e3503f",
      "e7a9959a89694a619f9ad8d62458fd51",
      "111f90e4751f49c0a62d0dcfe6e57d41",
      "9ed23ee348544a2887fcca33c72d3f56",
      "a516badeb7314612ba6c3a1d50749b24",
      "a8827469c20340d58ab9983bd0621a97",
      "ff2129dcef5d410db7fe3505ed07389a"
     ]
    },
    "id": "g0fVaJsj7GC-",
    "outputId": "da033b0f-fc5f-4038-9d04-d5ccaa4511bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:2046] 2024-03-02 11:55:20,667 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen1.5-0.5B-Chat/snapshots/6c705984bb8b5591dd4e1a9e66e1a127965fd08d/vocab.json\n",
      "[INFO|tokenization_utils_base.py:2046] 2024-03-02 11:55:20,669 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen1.5-0.5B-Chat/snapshots/6c705984bb8b5591dd4e1a9e66e1a127965fd08d/merges.txt\n",
      "[INFO|tokenization_utils_base.py:2046] 2024-03-02 11:55:20,671 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2046] 2024-03-02 11:55:20,673 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2046] 2024-03-02 11:55:20,675 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen1.5-0.5B-Chat/snapshots/6c705984bb8b5591dd4e1a9e66e1a127965fd08d/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2046] 2024-03-02 11:55:20,676 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen1.5-0.5B-Chat/snapshots/6c705984bb8b5591dd4e1a9e66e1a127965fd08d/tokenizer.json\n",
      "[WARNING|logging.py:314] 2024-03-02 11:55:20,949 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|configuration_utils.py:728] 2024-03-02 11:55:21,060 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen1.5-0.5B-Chat/snapshots/6c705984bb8b5591dd4e1a9e66e1a127965fd08d/config.json\n",
      "[INFO|configuration_utils.py:791] 2024-03-02 11:55:21,063 >> Model config Qwen2Config {\n",
      "  \"_name_or_path\": \"Qwen/Qwen1.5-0.5B-Chat\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2816,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 21,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_key_value_heads\": 16,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.38.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3257] 2024-03-02 11:55:21,067 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen1.5-0.5B-Chat/snapshots/6c705984bb8b5591dd4e1a9e66e1a127965fd08d/model.safetensors\n",
      "[INFO|modeling_utils.py:1400] 2024-03-02 11:55:21,086 >> Instantiating Qwen2ForCausalLM model under default dtype torch.float16.\n",
      "[INFO|configuration_utils.py:845] 2024-03-02 11:55:21,091 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3992] 2024-03-02 11:55:23,569 >> All model checkpoint weights were used when initializing Qwen2ForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4000] 2024-03-02 11:55:23,571 >> All the weights of Qwen2ForCausalLM were initialized from the model checkpoint at Qwen/Qwen1.5-0.5B-Chat.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:800] 2024-03-02 11:55:23,642 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen1.5-0.5B-Chat/snapshots/6c705984bb8b5591dd4e1a9e66e1a127965fd08d/generation_config.json\n",
      "[INFO|configuration_utils.py:845] 2024-03-02 11:55:23,644 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    151645,\n",
      "    151643\n",
      "  ],\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"repetition_penalty\": 1.1,\n",
      "  \"top_p\": 0.8\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/02/2024 11:55:23 - INFO - llmtuner.model.adapter - Fine-tuning method: LoRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llmtuner.model.adapter:Fine-tuning method: LoRA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/02/2024 11:55:24 - INFO - llmtuner.model.adapter - Merged 1 adapter(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llmtuner.model.adapter:Merged 1 adapter(s).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/02/2024 11:55:24 - INFO - llmtuner.model.adapter - Loaded adapter(s): test_identity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llmtuner.model.adapter:Loaded adapter(s): test_identity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/02/2024 11:55:24 - INFO - llmtuner.model.loader - all params: 463987712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llmtuner.model.loader:all params: 463987712\n",
      "[INFO|configuration_utils.py:473] 2024-03-02 11:55:24,827 >> Configuration saved in test_exported/config.json\n",
      "[INFO|configuration_utils.py:614] 2024-03-02 11:55:24,830 >> Configuration saved in test_exported/generation_config.json\n",
      "[INFO|modeling_utils.py:2454] 2024-03-02 11:55:28,709 >> Model weights saved in test_exported/model.safetensors\n",
      "[INFO|configuration_utils.py:473] 2024-03-02 11:55:29,104 >> Configuration saved in test_identity/config.json\n",
      "[INFO|configuration_utils.py:614] 2024-03-02 11:55:29,107 >> Configuration saved in test_identity/generation_config.json\n",
      "[INFO|modeling_utils.py:2454] 2024-03-02 11:55:32,848 >> Model weights saved in test_identity/model.safetensors\n",
      "[INFO|hub.py:757] 2024-03-02 11:55:35,732 >> Uploading the following files to hiyouga/test_identity: README.md,generation_config.json,model.safetensors,config.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1beb7d33abd741abbc2972bb48b4b9bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/928M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:2459] 2024-03-02 11:55:56,483 >> tokenizer config file saved in test_exported/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2468] 2024-03-02 11:55:56,485 >> Special tokens file saved in test_exported/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2519] 2024-03-02 11:55:56,487 >> added tokens file saved in test_exported/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bde6ae496a04435b40e0760af81f1a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:2459] 2024-03-02 11:55:57,200 >> tokenizer config file saved in test_identity/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2468] 2024-03-02 11:55:57,202 >> Special tokens file saved in test_identity/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2519] 2024-03-02 11:55:57,204 >> added tokens file saved in test_identity/added_tokens.json\n",
      "[INFO|hub.py:757] 2024-03-02 11:55:57,765 >> Uploading the following files to hiyouga/test_identity: README.md,added_tokens.json,vocab.json,special_tokens_map.json,merges.txt,tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "from llmtuner import export_model\n",
    "export_model(dict(\n",
    "  model_name_or_path=\"Qwen/Qwen1.5-0.5B-Chat\",\n",
    "  adapter_name_or_path=\"test_identity\",\n",
    "  finetuning_type=\"lora\",\n",
    "  template=\"qwen\",\n",
    "  export_dir=\"test_exported\",\n",
    "  # export_hub_model_id=\"your_hf_id/test_identity\",\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02f447d7943b49fb9b860445f5a5d5cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "03803cba8e7640cba253c4a09dcf4961": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d03d0201399f43068e9ac9f979805c7f",
      "placeholder": "​",
      "style": "IPY_MODEL_81b2131395914c19ba491985fa8e01e1",
      "value": "Converting format of dataset: 100%"
     }
    },
    "0569943b210a4e9a918d3f0be630f1df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2112a54c827f4d048e596058effbb660",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bf36698e9fdb4ebc9557dc2aa7095c6b",
      "value": 1
     }
    },
    "0633218a783f400398d1eeb270e3503f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "093800f206c547fe941aeb3922f03695": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0a00d77bcbc74b04bc375a854701f92f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d0c0c57b40854d2f940aff178fd44908",
      "placeholder": "​",
      "style": "IPY_MODEL_30664764c59e4b7895be3075e479cdad",
      "value": " 52002/0 [00:00&lt;00:00, 111696.61 examples/s]"
     }
    },
    "0b1a6ed426ed41f0b72cda3d74992ed9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0d906b908be04f82bd5d9324fcf4a734": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4148233d01014bbbaea6173f998ffbe3",
      "placeholder": "​",
      "style": "IPY_MODEL_bdd284f73de046e29dfc10378a6639d3",
      "value": " 500/500 [00:00&lt;00:00, 9258.21 examples/s]"
     }
    },
    "0e37aea1f0af438699f62b322cfb60e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "111f90e4751f49c0a62d0dcfe6e57d41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "119a55cb4316419d82b824fd6d1e3cc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "128a66c05a9e48a195b9f842971935c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_03803cba8e7640cba253c4a09dcf4961",
       "IPY_MODEL_22da0001b67c457589ed4a5b9a41b20d",
       "IPY_MODEL_24dc94877a96465abaa7200bfbab749d"
      ],
      "layout": "IPY_MODEL_e4c6bb9c97764e0a979c7247ac93c3fa"
     }
    },
    "13c2a6e951f74f5f90b0d84aa5eb06d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "159755c6de394e7d9c5a25907dc153b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1837d6e66f624fb2a865cada3c20083d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18e891e5c54048a29b56f46ade947b92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e945c0ff23ed405ab003fbb3bc128799",
       "IPY_MODEL_392bf66717c84ca4a67fa2b63631e705",
       "IPY_MODEL_c08eb3b86c644f648da1d7b5370466fc"
      ],
      "layout": "IPY_MODEL_1837d6e66f624fb2a865cada3c20083d"
     }
    },
    "195bfaa83de043fd97f9b5f1c79e44a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1a13f097ad494efbbb09561c3db5d54a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8827469c20340d58ab9983bd0621a97",
      "placeholder": "​",
      "style": "IPY_MODEL_ff2129dcef5d410db7fe3505ed07389a",
      "value": " 5.19k/5.19k [00:00&lt;00:00, 370kB/s]"
     }
    },
    "1b813a62b30d4ceea1f6bc4b3383454f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1beb7d33abd741abbc2972bb48b4b9bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_23d3a4d7f87245ae97859d77c01ef633",
       "IPY_MODEL_e58d8f51de494c34ae485289b23f90c9",
       "IPY_MODEL_a0f47c5484d6461e8f11398b279f1d9a"
      ],
      "layout": "IPY_MODEL_d9ef53356ff744849e7cb4c8e610bbea"
     }
    },
    "1d0c2f556975480d98889724a1b54324": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2112a54c827f4d048e596058effbb660": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "22da0001b67c457589ed4a5b9a41b20d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca7dd8105a5544bf81831fa864f7975c",
      "max": 91,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_093800f206c547fe941aeb3922f03695",
      "value": 91
     }
    },
    "23d3a4d7f87245ae97859d77c01ef633": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7f05924d910420c884464799a623a87",
      "placeholder": "​",
      "style": "IPY_MODEL_159755c6de394e7d9c5a25907dc153b5",
      "value": "model.safetensors: 100%"
     }
    },
    "24008a18243a4f25a0ec1fd81f510503": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_378463ca76cd4dbcbc4ce39a3f38373d",
       "IPY_MODEL_aeadef38e6c24751aac9a109dc4f8d24",
       "IPY_MODEL_734376de3bc6425b81e30804f29a60a9"
      ],
      "layout": "IPY_MODEL_bcd1efe0682d46dba2f37224b23b479f"
     }
    },
    "24dc94877a96465abaa7200bfbab749d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da9e68d589e345cca595cecb1d0e7996",
      "placeholder": "​",
      "style": "IPY_MODEL_119a55cb4316419d82b824fd6d1e3cc3",
      "value": " 91/91 [00:00&lt;00:00, 2582.89 examples/s]"
     }
    },
    "2bde6ae496a04435b40e0760af81f1a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f4c5e9c5f07f4778877143f4bcad4604",
       "IPY_MODEL_eb890d67981944b48e573e8c6fc25853",
       "IPY_MODEL_1a13f097ad494efbbb09561c3db5d54a"
      ],
      "layout": "IPY_MODEL_0633218a783f400398d1eeb270e3503f"
     }
    },
    "30664764c59e4b7895be3075e479cdad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "34e7f3d5e9bb4c279a58e39a457b8825": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "378463ca76cd4dbcbc4ce39a3f38373d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b813a62b30d4ceea1f6bc4b3383454f",
      "placeholder": "​",
      "style": "IPY_MODEL_5f4ad5b09e2e441685aa38b42d0b2815",
      "value": "Running tokenizer on dataset: 100%"
     }
    },
    "392bf66717c84ca4a67fa2b63631e705": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b491a63d00c14c64a98a9be4ff6a6349",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_554543172a8f42629b8fc01313fa2fd9",
      "value": 1
     }
    },
    "3d17e37c7ba64b7d84f4fe4586761a9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4148233d01014bbbaea6173f998ffbe3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43986f9e13c0407c8a8e211569b1dc85": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "439e867ccc8b4260b51778f12190d168": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b5966cf051f544ddbe502d0b0c698677",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a04d61033d7042adae9deacad48ba267",
      "value": 1
     }
    },
    "474b504682d44fc7a38ff6b6fe537990": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4b10a7dbe085446a94d3ab3762ee16e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_547d15abbe1243e5a21f71c292bc1457",
      "placeholder": "​",
      "style": "IPY_MODEL_c803604b47bb4b9197cfc16dc0d61725",
      "value": "Generating train split: "
     }
    },
    "4f1afb920d364765afb03c38615c94ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "547d15abbe1243e5a21f71c292bc1457": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "554543172a8f42629b8fc01313fa2fd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5f4ad5b09e2e441685aa38b42d0b2815": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6032c6dd0cc84498a8779492034a0564": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "64181e96c6db484c8bcd9c5e5f9c4421": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66b0f1f7e9fd484d816a397483ecaace": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f726bea48d54f41952fe0a64db948ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0e37aea1f0af438699f62b322cfb60e5",
      "placeholder": "​",
      "style": "IPY_MODEL_34e7f3d5e9bb4c279a58e39a457b8825",
      "value": "Converting format of dataset: 100%"
     }
    },
    "721f5318688e449ca3d9d43ecbe9451b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "734376de3bc6425b81e30804f29a60a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7524a8bcffed4f9099a70e29a5f6d136",
      "placeholder": "​",
      "style": "IPY_MODEL_7e4309f5c2cf4e699de5359b1b2d2ae9",
      "value": " 1091/1091 [00:04&lt;00:00, 217.62 examples/s]"
     }
    },
    "7363b9307d144353a165de3cb2320043": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7524a8bcffed4f9099a70e29a5f6d136": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7602853a84424a93ab04fb9f300d04ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7878d5b1a5404df5b0f227088155e754": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_abf6c990b29e4e03bc7ebd4b8a97137c",
       "IPY_MODEL_97aac7dd3d1749bebb33c0e8fff3d113",
       "IPY_MODEL_b540dea4a46d4c39bdac9980bff70792"
      ],
      "layout": "IPY_MODEL_bfd01522a6874ec3933143acf290b6e4"
     }
    },
    "7e4309f5c2cf4e699de5359b1b2d2ae9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7e72fa317d6e401d8e1e403d833b6c0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4b10a7dbe085446a94d3ab3762ee16e4",
       "IPY_MODEL_439e867ccc8b4260b51778f12190d168",
       "IPY_MODEL_d4269a09d2bd49be96faa8c706ad86ec"
      ],
      "layout": "IPY_MODEL_7602853a84424a93ab04fb9f300d04ab"
     }
    },
    "7f1512d7f38740548588d12d46e9a438": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f1e958f89e747799b020921f2d33e75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43986f9e13c0407c8a8e211569b1dc85",
      "placeholder": "​",
      "style": "IPY_MODEL_9dd4ce468c77496e997d54d40ae9479c",
      "value": "Generating train split: "
     }
    },
    "806b6e6df1a64a67b547e542f1c3d4f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "81b2131395914c19ba491985fa8e01e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "82b8d24eb5ad405394bf49ee1e48475b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "833be6f72a28451bb5f9ca1659c28925": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "97aac7dd3d1749bebb33c0e8fff3d113": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9804e61cd770426fa3a9351c476e0339",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0b1a6ed426ed41f0b72cda3d74992ed9",
      "value": 500
     }
    },
    "9804e61cd770426fa3a9351c476e0339": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "999f31445d7e42afba2d504f1f02a2f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9dd4ce468c77496e997d54d40ae9479c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9ed23ee348544a2887fcca33c72d3f56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a04d61033d7042adae9deacad48ba267": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a0f47c5484d6461e8f11398b279f1d9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f1512d7f38740548588d12d46e9a438",
      "placeholder": "​",
      "style": "IPY_MODEL_195bfaa83de043fd97f9b5f1c79e44a1",
      "value": " 928M/928M [00:19&lt;00:00, 39.6MB/s]"
     }
    },
    "a516badeb7314612ba6c3a1d50749b24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a7f05924d910420c884464799a623a87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8827469c20340d58ab9983bd0621a97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "abf6c990b29e4e03bc7ebd4b8a97137c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66b0f1f7e9fd484d816a397483ecaace",
      "placeholder": "​",
      "style": "IPY_MODEL_833be6f72a28451bb5f9ca1659c28925",
      "value": "Converting format of dataset: 100%"
     }
    },
    "aeadef38e6c24751aac9a109dc4f8d24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82b8d24eb5ad405394bf49ee1e48475b",
      "max": 1091,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_474b504682d44fc7a38ff6b6fe537990",
      "value": 1091
     }
    },
    "b001f63c495346aaabbd750ec07d5ef4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b491a63d00c14c64a98a9be4ff6a6349": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "b540dea4a46d4c39bdac9980bff70792": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d0c2f556975480d98889724a1b54324",
      "placeholder": "​",
      "style": "IPY_MODEL_7363b9307d144353a165de3cb2320043",
      "value": " 500/500 [00:00&lt;00:00, 12469.24 examples/s]"
     }
    },
    "b5966cf051f544ddbe502d0b0c698677": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "bcd1efe0682d46dba2f37224b23b479f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdd284f73de046e29dfc10378a6639d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf36698e9fdb4ebc9557dc2aa7095c6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bfd01522a6874ec3933143acf290b6e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c08eb3b86c644f648da1d7b5370466fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_721f5318688e449ca3d9d43ecbe9451b",
      "placeholder": "​",
      "style": "IPY_MODEL_6032c6dd0cc84498a8779492034a0564",
      "value": " 91/0 [00:00&lt;00:00, 2495.12 examples/s]"
     }
    },
    "c803604b47bb4b9197cfc16dc0d61725": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ca7dd8105a5544bf81831fa864f7975c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb24a2b941284c00a59c60aa521b67fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d17e37c7ba64b7d84f4fe4586761a9e",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_999f31445d7e42afba2d504f1f02a2f5",
      "value": 500
     }
    },
    "d03d0201399f43068e9ac9f979805c7f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0c0c57b40854d2f940aff178fd44908": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d205bd683425483abdd970d6a4ecbe24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7f1e958f89e747799b020921f2d33e75",
       "IPY_MODEL_0569943b210a4e9a918d3f0be630f1df",
       "IPY_MODEL_0a00d77bcbc74b04bc375a854701f92f"
      ],
      "layout": "IPY_MODEL_4f1afb920d364765afb03c38615c94ce"
     }
    },
    "d4269a09d2bd49be96faa8c706ad86ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e8da4d8db24541c694a4456dab99712e",
      "placeholder": "​",
      "style": "IPY_MODEL_e7628413721445919ecbf674f747b91c",
      "value": " 48818/0 [00:00&lt;00:00, 84825.17 examples/s]"
     }
    },
    "d9ef53356ff744849e7cb4c8e610bbea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da9e68d589e345cca595cecb1d0e7996": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4c6bb9c97764e0a979c7247ac93c3fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e58d8f51de494c34ae485289b23f90c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_64181e96c6db484c8bcd9c5e5f9c4421",
      "max": 928008104,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_806b6e6df1a64a67b547e542f1c3d4f9",
      "value": 928008104
     }
    },
    "e7628413721445919ecbf674f747b91c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e7a730f7e6ff446fae05c52f022161ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6f726bea48d54f41952fe0a64db948ac",
       "IPY_MODEL_cb24a2b941284c00a59c60aa521b67fd",
       "IPY_MODEL_0d906b908be04f82bd5d9324fcf4a734"
      ],
      "layout": "IPY_MODEL_b001f63c495346aaabbd750ec07d5ef4"
     }
    },
    "e7a9959a89694a619f9ad8d62458fd51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8da4d8db24541c694a4456dab99712e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e945c0ff23ed405ab003fbb3bc128799": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_02f447d7943b49fb9b860445f5a5d5cf",
      "placeholder": "​",
      "style": "IPY_MODEL_13c2a6e951f74f5f90b0d84aa5eb06d4",
      "value": "Generating train split: "
     }
    },
    "eb890d67981944b48e573e8c6fc25853": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ed23ee348544a2887fcca33c72d3f56",
      "max": 5191,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a516badeb7314612ba6c3a1d50749b24",
      "value": 5191
     }
    },
    "f4c5e9c5f07f4778877143f4bcad4604": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e7a9959a89694a619f9ad8d62458fd51",
      "placeholder": "​",
      "style": "IPY_MODEL_111f90e4751f49c0a62d0dcfe6e57d41",
      "value": "README.md: 100%"
     }
    },
    "ff2129dcef5d410db7fe3505ed07389a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
